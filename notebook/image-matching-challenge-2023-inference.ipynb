{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dec0406",
   "metadata": {
    "papermill": {
     "duration": 0.01018,
     "end_time": "2023-05-28T15:44:53.697761",
     "exception": false,
     "start_time": "2023-05-28T15:44:53.687581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "800fe30e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-28T15:44:53.716225Z",
     "iopub.status.busy": "2023-05-28T15:44:53.715432Z",
     "iopub.status.idle": "2023-05-28T15:45:08.114591Z",
     "shell.execute_reply": "2023-05-28T15:45:08.113110Z"
    },
    "papermill": {
     "duration": 14.412454,
     "end_time": "2023-05-28T15:45:08.118422",
     "exception": false,
     "start_time": "2023-05-28T15:44:53.705968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import h5py\n",
    "from glob import glob\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ExifTags\n",
    "import cv2\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler\n",
    "import timm\n",
    "import kornia\n",
    "from kornia.feature import LoFTR\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import pycolmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff7a45b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:08.155095Z",
     "iopub.status.busy": "2023-05-28T15:45:08.154490Z",
     "iopub.status.idle": "2023-05-28T15:45:08.162369Z",
     "shell.execute_reply": "2023-05-28T15:45:08.159670Z"
    },
    "papermill": {
     "duration": 0.029432,
     "end_time": "2023-05-28T15:45:08.165516",
     "exception": false,
     "start_time": "2023-05-28T15:45:08.136084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "competition_dataset = Path('/kaggle/input/image-matching-challenge-2023')\n",
    "external_dataset = Path('/kaggle/input/image-matching-challenge-2023-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dade3e2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:08.191074Z",
     "iopub.status.busy": "2023-05-28T15:45:08.190805Z",
     "iopub.status.idle": "2023-05-28T15:45:08.240412Z",
     "shell.execute_reply": "2023-05-28T15:45:08.239587Z"
    },
    "papermill": {
     "duration": 0.060876,
     "end_time": "2023-05-28T15:45:08.242880",
     "exception": false,
     "start_time": "2023-05-28T15:45:08.182004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(str(external_dataset / 'packages' / 'SuperGluePretrainedNetwork'))\n",
    "from models.matching import Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc06317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:08.261021Z",
     "iopub.status.busy": "2023-05-28T15:45:08.260207Z",
     "iopub.status.idle": "2023-05-28T15:45:09.138498Z",
     "shell.execute_reply": "2023-05-28T15:45:09.137637Z"
    },
    "papermill": {
     "duration": 0.889346,
     "end_time": "2023-05-28T15:45:09.140537",
     "exception": false,
     "start_time": "2023-05-28T15:45:08.251191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 17.87it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(competition_dataset / 'sample_submission.csv')\n",
    "\n",
    "if df.shape[0] != 3:\n",
    "    # Enable submission mode and disable verbose\n",
    "    submission = True\n",
    "    verbose = False\n",
    "    train_or_test_directory = competition_dataset / 'test'\n",
    "else:\n",
    "    # Disable submission mode and enable verbose\n",
    "    submission = False\n",
    "    verbose = True\n",
    "    train_or_test_directory = competition_dataset / 'train'\n",
    "\n",
    "if submission is False:\n",
    "    df = pd.read_csv(competition_dataset / 'train' / 'train_labels.csv')\n",
    "    # Use only bike scene from the haiper dataset if it's not submission mode\n",
    "    df = df.loc[df['scene'] == 'bike'].reset_index(drop=True)\n",
    "    \n",
    "# Extract image id, image height and image width from images\n",
    "for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "\n",
    "    image_path = train_or_test_directory / row['image_path']\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    df.loc[idx, 'image_height'] = image.shape[0]\n",
    "    df.loc[idx, 'image_width'] = image.shape[1]\n",
    "\n",
    "\n",
    "df['image_id'] = df['image_path'].apply(lambda x: str(x).split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb6e9792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:09.160199Z",
     "iopub.status.busy": "2023-05-28T15:45:09.159410Z",
     "iopub.status.idle": "2023-05-28T15:45:09.180239Z",
     "shell.execute_reply": "2023-05-28T15:45:09.179252Z"
    },
    "papermill": {
     "duration": 0.033075,
     "end_time": "2023-05-28T15:45:09.182780",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.149705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>scene</th>\n",
       "      <th>image_path</th>\n",
       "      <th>rotation_matrix</th>\n",
       "      <th>translation_vector</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_004.jpeg</td>\n",
       "      <td>-0.0444086367008516;-0.9943622104926982;0.0962...</td>\n",
       "      <td>-0.1960672197513899;-1.7201514631645476;2.9038...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_004.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_029.jpeg</td>\n",
       "      <td>-0.30379429789458934;-0.780428110344117;0.5464...</td>\n",
       "      <td>-0.7743795049636117;-2.4063622468195978;4.2039...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_029.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_038.jpeg</td>\n",
       "      <td>-0.44075875074949056;-0.6141344795467536;0.654...</td>\n",
       "      <td>-0.8061619977689489;-1.3614914099692277;2.5759...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_038.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_049.jpeg</td>\n",
       "      <td>-0.4615070783507189;-0.037215312681071866;0.88...</td>\n",
       "      <td>-0.05029237007998646;-2.0953351075544067;3.128...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_049.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_062.jpeg</td>\n",
       "      <td>0.06454466684801141;0.9943063402602297;0.08478...</td>\n",
       "      <td>0.45813698932578173;-1.7352377000311676;3.6787...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_062.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_076.jpeg</td>\n",
       "      <td>0.566876909470875;-0.09510152245268588;-0.8182...</td>\n",
       "      <td>1.1496049380742543;-1.4930263438651057;2.57378...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_076.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_088.jpeg</td>\n",
       "      <td>0.253507028584536;-0.8760074072730466;-0.41029...</td>\n",
       "      <td>-0.44871563031823725;-1.750899302580256;2.6802...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_088.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_094.jpeg</td>\n",
       "      <td>0.15438718127182738;-0.9293944893965761;-0.335...</td>\n",
       "      <td>-0.37595896679394963;-2.714322519243274;4.1322...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_094.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_101.jpeg</td>\n",
       "      <td>0.4234658773801474;-0.6722258122106511;-0.6072...</td>\n",
       "      <td>-0.11276896793699917;-0.7117396520115244;1.914...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_101.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_115.jpeg</td>\n",
       "      <td>0.3904043657227909;0.16367189264027227;-0.9059...</td>\n",
       "      <td>0.8296975499797659;-2.3480417943432315;3.47250...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_115.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_119.jpeg</td>\n",
       "      <td>0.34139276573704824;0.81351456101145;-0.470791...</td>\n",
       "      <td>-0.10007794513469218;-2.544833204003964;4.0417...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_119.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_128.jpeg</td>\n",
       "      <td>-0.2177248850251865;0.694914687853886;0.685338...</td>\n",
       "      <td>-1.1094352034062702;-2.5456449855138703;4.5788...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_128.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_137.jpeg</td>\n",
       "      <td>0.22425244568562896;0.8687843075194276;-0.4415...</td>\n",
       "      <td>0.7847615822482943;-0.25685464008216424;3.3788...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_137.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_139.jpeg</td>\n",
       "      <td>0.45484758018631954;0.5331256298557034;-0.7133...</td>\n",
       "      <td>1.0869579831200566;-1.5594034733929556;3.04410...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_139.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>haiper/bike/images/image_150.jpeg</td>\n",
       "      <td>0.5749716111003644;-0.2792314233637461;-0.7690...</td>\n",
       "      <td>0.42673787089296894;-1.8688015981412343;2.7976...</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>image_150.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset scene                         image_path  \\\n",
       "0   haiper  bike  haiper/bike/images/image_004.jpeg   \n",
       "1   haiper  bike  haiper/bike/images/image_029.jpeg   \n",
       "2   haiper  bike  haiper/bike/images/image_038.jpeg   \n",
       "3   haiper  bike  haiper/bike/images/image_049.jpeg   \n",
       "4   haiper  bike  haiper/bike/images/image_062.jpeg   \n",
       "5   haiper  bike  haiper/bike/images/image_076.jpeg   \n",
       "6   haiper  bike  haiper/bike/images/image_088.jpeg   \n",
       "7   haiper  bike  haiper/bike/images/image_094.jpeg   \n",
       "8   haiper  bike  haiper/bike/images/image_101.jpeg   \n",
       "9   haiper  bike  haiper/bike/images/image_115.jpeg   \n",
       "10  haiper  bike  haiper/bike/images/image_119.jpeg   \n",
       "11  haiper  bike  haiper/bike/images/image_128.jpeg   \n",
       "12  haiper  bike  haiper/bike/images/image_137.jpeg   \n",
       "13  haiper  bike  haiper/bike/images/image_139.jpeg   \n",
       "14  haiper  bike  haiper/bike/images/image_150.jpeg   \n",
       "\n",
       "                                      rotation_matrix  \\\n",
       "0   -0.0444086367008516;-0.9943622104926982;0.0962...   \n",
       "1   -0.30379429789458934;-0.780428110344117;0.5464...   \n",
       "2   -0.44075875074949056;-0.6141344795467536;0.654...   \n",
       "3   -0.4615070783507189;-0.037215312681071866;0.88...   \n",
       "4   0.06454466684801141;0.9943063402602297;0.08478...   \n",
       "5   0.566876909470875;-0.09510152245268588;-0.8182...   \n",
       "6   0.253507028584536;-0.8760074072730466;-0.41029...   \n",
       "7   0.15438718127182738;-0.9293944893965761;-0.335...   \n",
       "8   0.4234658773801474;-0.6722258122106511;-0.6072...   \n",
       "9   0.3904043657227909;0.16367189264027227;-0.9059...   \n",
       "10  0.34139276573704824;0.81351456101145;-0.470791...   \n",
       "11  -0.2177248850251865;0.694914687853886;0.685338...   \n",
       "12  0.22425244568562896;0.8687843075194276;-0.4415...   \n",
       "13  0.45484758018631954;0.5331256298557034;-0.7133...   \n",
       "14  0.5749716111003644;-0.2792314233637461;-0.7690...   \n",
       "\n",
       "                                   translation_vector  image_height  \\\n",
       "0   -0.1960672197513899;-1.7201514631645476;2.9038...        1920.0   \n",
       "1   -0.7743795049636117;-2.4063622468195978;4.2039...        1920.0   \n",
       "2   -0.8061619977689489;-1.3614914099692277;2.5759...        1920.0   \n",
       "3   -0.05029237007998646;-2.0953351075544067;3.128...        1920.0   \n",
       "4   0.45813698932578173;-1.7352377000311676;3.6787...        1920.0   \n",
       "5   1.1496049380742543;-1.4930263438651057;2.57378...        1920.0   \n",
       "6   -0.44871563031823725;-1.750899302580256;2.6802...        1920.0   \n",
       "7   -0.37595896679394963;-2.714322519243274;4.1322...        1920.0   \n",
       "8   -0.11276896793699917;-0.7117396520115244;1.914...        1920.0   \n",
       "9   0.8296975499797659;-2.3480417943432315;3.47250...        1920.0   \n",
       "10  -0.10007794513469218;-2.544833204003964;4.0417...        1920.0   \n",
       "11  -1.1094352034062702;-2.5456449855138703;4.5788...        1920.0   \n",
       "12  0.7847615822482943;-0.25685464008216424;3.3788...        1920.0   \n",
       "13  1.0869579831200566;-1.5594034733929556;3.04410...        1920.0   \n",
       "14  0.42673787089296894;-1.8688015981412343;2.7976...        1920.0   \n",
       "\n",
       "    image_width        image_id  \n",
       "0        1440.0  image_004.jpeg  \n",
       "1        1440.0  image_029.jpeg  \n",
       "2        1440.0  image_038.jpeg  \n",
       "3        1440.0  image_049.jpeg  \n",
       "4        1440.0  image_062.jpeg  \n",
       "5        1440.0  image_076.jpeg  \n",
       "6        1440.0  image_088.jpeg  \n",
       "7        1440.0  image_094.jpeg  \n",
       "8        1440.0  image_101.jpeg  \n",
       "9        1440.0  image_115.jpeg  \n",
       "10       1440.0  image_119.jpeg  \n",
       "11       1440.0  image_128.jpeg  \n",
       "12       1440.0  image_137.jpeg  \n",
       "13       1440.0  image_139.jpeg  \n",
       "14       1440.0  image_150.jpeg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6cbeb",
   "metadata": {
    "papermill": {
     "duration": 0.009076,
     "end_time": "2023-05-28T15:45:09.200999",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.191923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Image Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f8deef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:09.220692Z",
     "iopub.status.busy": "2023-05-28T15:45:09.220422Z",
     "iopub.status.idle": "2023-05-28T15:45:09.231681Z",
     "shell.execute_reply": "2023-05-28T15:45:09.230704Z"
    },
    "papermill": {
     "duration": 0.023434,
     "end_time": "2023-05-28T15:45:09.233635",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.210201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_image_pairs(image_paths):\n",
    "\n",
    "    \"\"\"\n",
    "    Create all possible image pairs from given list of image paths\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_paths: list of shape (n_images)\n",
    "        List of image paths\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image_pair_indices: list of shape (n_image_pairs)\n",
    "        List of tuples of image pair indices\n",
    "    \"\"\"\n",
    "\n",
    "    image_pair_indices = []\n",
    "\n",
    "    for i in range(len(image_paths)):\n",
    "        for j in range(i + 1, len(image_paths)):\n",
    "            image_pair_indices.append((i, j))\n",
    "\n",
    "    return image_pair_indices\n",
    "\n",
    "\n",
    "def resize_with_aspect_ratio(image, longest_edge):\n",
    "\n",
    "    \"\"\"\n",
    "    Resize image while preserving its aspect ratio\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: numpy.ndarray of shape (height, width, 3)\n",
    "        Image array\n",
    "\n",
    "    longest_edge: int\n",
    "        Desired number of pixels on the longest edge\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image: numpy.ndarray of shape (resized_height, resized_width, 3)\n",
    "        Resized image array\n",
    "    \"\"\"\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "    scale = longest_edge / max(height, width)\n",
    "    image = cv2.resize(image, dsize=(int(width * scale), int(height * scale)), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_image_tensor(image_path_or_array, resize, resize_shape, resize_longest_edge, scale, grayscale):\n",
    "\n",
    "    \"\"\"\n",
    "    Load image and preprocess it\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path_or_array: str or numpy.ndarray of shape (height, width, 3)\n",
    "        Image path or image array\n",
    "\n",
    "    resize: bool\n",
    "        Whether to resize the image or not\n",
    "\n",
    "    resize_shape: tuple or int\n",
    "        Tuple of image height and width or number of pixels for both height and width\n",
    "\n",
    "    resize_longest_edge: bool\n",
    "        Whether to resize the longest edge or not\n",
    "\n",
    "    scale: bool\n",
    "        Whether to scale image pixel values by max 8-bit pixel value or not\n",
    "\n",
    "    grayscale: bool\n",
    "        Whether to convert RGB image to grayscale or not\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image: torch.Tensor of shape (1, 1 or 3, height, width)\n",
    "        Image tensor\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(image_path_or_array, pathlib.Path) or isinstance(image_path_or_array, str):\n",
    "        # Read image from the given path if image_path_or_array is a path-like string\n",
    "        image = cv2.imread(str(image_path_or_array))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        image = image_path_or_array\n",
    "\n",
    "    if resize:\n",
    "        if resize_longest_edge:\n",
    "            image = resize_with_aspect_ratio(image=image, longest_edge=resize_shape)\n",
    "        else:\n",
    "            resize_shape = (resize_shape, resize_shape) if isinstance(resize_shape, int) else resize_shape\n",
    "            image = cv2.resize(image, resize_shape, interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "    if scale:\n",
    "        image = image / 255.\n",
    "\n",
    "    image = kornia.image_to_tensor(image, False).float()\n",
    "    if grayscale:\n",
    "        image = kornia.color.rgb_to_grayscale(image)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a76f78",
   "metadata": {
    "papermill": {
     "duration": 0.008894,
     "end_time": "2023-05-28T15:45:09.251945",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.243051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Camera Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61160498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:09.271343Z",
     "iopub.status.busy": "2023-05-28T15:45:09.271049Z",
     "iopub.status.idle": "2023-05-28T15:45:09.277960Z",
     "shell.execute_reply": "2023-05-28T15:45:09.277122Z"
    },
    "papermill": {
     "duration": 0.018869,
     "end_time": "2023-05-28T15:45:09.279895",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.261026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_focal_length(image_path):\n",
    "\n",
    "    \"\"\"\n",
    "    Get focal length from EXIF or calculate it using prior\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path: str\n",
    "        Image path\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    focal_length: float\n",
    "        Focal length extracted from EXIF or calculated using prior\n",
    "    \"\"\"\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    image_longest_edge = max(image.size)\n",
    "\n",
    "    focal_length = None\n",
    "    exif = image.getexif()\n",
    "\n",
    "    if exif is not None:\n",
    "\n",
    "        focal_length_35mm = None\n",
    "\n",
    "        for tag, value in exif.items():\n",
    "            if ExifTags.TAGS.get(tag, None) == 'FocalLengthIn35mmFilm':\n",
    "                focal_length_35mm = float(value)\n",
    "\n",
    "        if focal_length_35mm is not None:\n",
    "            focal_length = focal_length_35mm / 35. * image_longest_edge\n",
    "\n",
    "    if focal_length is None:\n",
    "        prior_focal_length = 1.2\n",
    "        focal_length = prior_focal_length * image_longest_edge\n",
    "\n",
    "    return focal_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb37c5fb",
   "metadata": {
    "papermill": {
     "duration": 0.008992,
     "end_time": "2023-05-28T15:45:09.298001",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.289009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Database Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e98b32c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:09.320327Z",
     "iopub.status.busy": "2023-05-28T15:45:09.320024Z",
     "iopub.status.idle": "2023-05-28T15:45:09.379466Z",
     "shell.execute_reply": "2023-05-28T15:45:09.378521Z"
    },
    "papermill": {
     "duration": 0.072379,
     "end_time": "2023-05-28T15:45:09.381875",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.309496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_IMAGE_ID = 2 ** 31 - 1\n",
    "\n",
    "CREATE_CAMERAS_TABLE_QUERY = '''\n",
    "CREATE TABLE IF NOT EXISTS cameras (\n",
    "    camera_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "    model INTEGER NOT NULL,\n",
    "    width INTEGER NOT NULL,\n",
    "    height INTEGER NOT NULL,\n",
    "    params BLOB,\n",
    "    prior_focal_length INTEGER NOT NULL\n",
    ")\n",
    "'''\n",
    "\n",
    "CREATE_IMAGES_TABLE_QUERY = f'''\n",
    "CREATE TABLE IF NOT EXISTS images (\n",
    "    image_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "    name TEXT NOT NULL UNIQUE,\n",
    "    camera_id INTEGER NOT NULL,\n",
    "    prior_qw REAL,\n",
    "    prior_qx REAL,\n",
    "    prior_qy REAL,\n",
    "    prior_qz REAL,\n",
    "    prior_tx REAL,\n",
    "    prior_ty REAL,\n",
    "    prior_tz REAL,\n",
    "    CONSTRAINT image_id_check CHECK(image_id >= 0 and image_id < {MAX_IMAGE_ID}),\n",
    "    FOREIGN KEY(camera_id) REFERENCES cameras(camera_id)\n",
    ")\n",
    "'''\n",
    "\n",
    "CREATE_DESCRIPTORS_TABLE_QUERY = '''\n",
    "CREATE TABLE IF NOT EXISTS descriptors (\n",
    "    image_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB,\n",
    "    FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE\n",
    ")\n",
    "'''\n",
    "\n",
    "CREATE_KEYPOINTS_TABLE_QUERY = '''CREATE TABLE IF NOT EXISTS keypoints (\n",
    "    image_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB,\n",
    "    FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE\n",
    ")\n",
    "'''\n",
    "\n",
    "CREATE_MATCHES_TABLE_QUERY = '''\n",
    "CREATE TABLE IF NOT EXISTS matches (\n",
    "    pair_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB\n",
    ")\n",
    "'''\n",
    "\n",
    "CREATE_TWO_VIEW_GEOMETRIES_TABLE_QUERY = '''\n",
    "CREATE TABLE IF NOT EXISTS two_view_geometries (\n",
    "    pair_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB,\n",
    "    config INTEGER NOT NULL,\n",
    "    F BLOB,\n",
    "    E BLOB,\n",
    "    H BLOB\n",
    ")\n",
    "'''\n",
    "\n",
    "CREATE_NAME_INDEX_QUERY = 'CREATE UNIQUE INDEX IF NOT EXISTS index_name ON images(name)'\n",
    "\n",
    "CREATE_ALL_QUERY = '; '.join([\n",
    "    CREATE_CAMERAS_TABLE_QUERY,\n",
    "    CREATE_IMAGES_TABLE_QUERY,\n",
    "    CREATE_KEYPOINTS_TABLE_QUERY,\n",
    "    CREATE_DESCRIPTORS_TABLE_QUERY,\n",
    "    CREATE_MATCHES_TABLE_QUERY,\n",
    "    CREATE_TWO_VIEW_GEOMETRIES_TABLE_QUERY,\n",
    "    CREATE_NAME_INDEX_QUERY\n",
    "])\n",
    "\n",
    "\n",
    "def blob_to_array(x):\n",
    "    if x is not None:\n",
    "        return np.frombuffer(x)\n",
    "\n",
    "\n",
    "def array_to_blob(x):\n",
    "    return np.asarray(x).tobytes()\n",
    "\n",
    "\n",
    "def image_ids_to_pair_id(image1_id, image2_id):\n",
    "    if image1_id > image2_id:\n",
    "        image1_id, image2_id = image2_id, image1_id\n",
    "    return image1_id * MAX_IMAGE_ID + image2_id\n",
    "\n",
    "\n",
    "def pair_id_to_image_ids(pair_id):\n",
    "    image_id2 = pair_id % MAX_IMAGE_ID\n",
    "    image_id1 = (pair_id - image_id2) / MAX_IMAGE_ID\n",
    "    return image_id1, image_id2\n",
    "\n",
    "\n",
    "class COLMAPDatabase(sqlite3.Connection):\n",
    "\n",
    "    @staticmethod\n",
    "    def connect(database_path, uri):\n",
    "        return sqlite3.connect(database_path, uri=uri, factory=COLMAPDatabase)\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "\n",
    "        super(COLMAPDatabase, self).__init__(*args, **kwargs)\n",
    "\n",
    "        self.create_tables = lambda: self.executescript(CREATE_ALL_QUERY)\n",
    "        self.create_cameras_table = lambda: self.executescript(CREATE_CAMERAS_TABLE_QUERY)\n",
    "        self.create_descriptors_table = lambda: self.executescript(CREATE_DESCRIPTORS_TABLE_QUERY)\n",
    "        self.create_images_table = lambda: self.executescript(CREATE_IMAGES_TABLE_QUERY)\n",
    "        self.create_two_view_geometries_table = lambda: self.executescript(CREATE_TWO_VIEW_GEOMETRIES_TABLE_QUERY)\n",
    "        self.create_keypoints_table = lambda: self.executescript(CREATE_KEYPOINTS_TABLE_QUERY)\n",
    "        self.create_matches_table = lambda: self.executescript(CREATE_MATCHES_TABLE_QUERY)\n",
    "        self.create_name_index = lambda: self.executescript(CREATE_NAME_INDEX_QUERY)\n",
    "\n",
    "    def get_cameras_table(self):\n",
    "\n",
    "        df_cameras = pd.read_sql('SELECT * FROM cameras', con=self)\n",
    "        if df_cameras.shape[0] > 0:\n",
    "            df_cameras['params'] = df_cameras['params'].apply(lambda x: blob_to_array(x))\n",
    "\n",
    "        return df_cameras\n",
    "\n",
    "    def get_images_table(self):\n",
    "\n",
    "        df_images = pd.read_sql('SELECT * FROM images', con=self)\n",
    "\n",
    "        return df_images\n",
    "\n",
    "    def get_descriptors_table(self):\n",
    "\n",
    "        df_descriptors = pd.read_sql('SELECT * FROM descriptors', con=self)\n",
    "        if df_descriptors.shape[0] > 0:\n",
    "            df_descriptors['data'] = df_descriptors['data'].apply(lambda x: blob_to_array(x))\n",
    "\n",
    "        return df_descriptors\n",
    "\n",
    "    def get_keypoints_table(self):\n",
    "\n",
    "        df_keypoints = pd.read_sql('SELECT * FROM keypoints', con=self)\n",
    "        if df_keypoints.shape[0] > 0:\n",
    "            df_keypoints['data'] = df_keypoints['data'].apply(lambda x: blob_to_array(x))\n",
    "\n",
    "        return df_keypoints\n",
    "\n",
    "    def get_matches_table(self):\n",
    "\n",
    "        df_matches = pd.read_sql('SELECT * FROM matches', con=self)\n",
    "        if df_matches.shape[0] > 0:\n",
    "            df_matches['data'] = df_matches['data'].apply(lambda x: blob_to_array(x))\n",
    "\n",
    "        return df_matches\n",
    "\n",
    "    def get_two_view_geometries_table(self):\n",
    "\n",
    "        df_two_view_geometries = pd.read_sql('SELECT * FROM two_view_geometries', con=self)\n",
    "        if df_two_view_geometries.shape[0] > 0:\n",
    "            df_two_view_geometries['data'] = df_two_view_geometries['data'].apply(lambda x: blob_to_array(x))\n",
    "            df_two_view_geometries['F'] = df_two_view_geometries['F'].apply(lambda x: blob_to_array(x))\n",
    "            df_two_view_geometries['E'] = df_two_view_geometries['E'].apply(lambda x: blob_to_array(x))\n",
    "            df_two_view_geometries['H'] = df_two_view_geometries['H'].apply(lambda x: blob_to_array(x))\n",
    "            df_two_view_geometries['qvec'] = df_two_view_geometries['qvec'].apply(lambda x: blob_to_array(x))\n",
    "            df_two_view_geometries['tvec'] = df_two_view_geometries['tvec'].apply(lambda x: blob_to_array(x))\n",
    "\n",
    "        return df_two_view_geometries\n",
    "\n",
    "    def add_camera(self, camera_id, model, width, height, params, prior_focal_length):\n",
    "\n",
    "        cursor = self.execute(\n",
    "            'INSERT INTO cameras VALUES (?, ?, ?, ?, ?, ?)',\n",
    "            (\n",
    "                camera_id,\n",
    "                model,\n",
    "                width,\n",
    "                height,\n",
    "                array_to_blob(params),\n",
    "                prior_focal_length\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return cursor.lastrowid\n",
    "\n",
    "    def add_image(self, image_id, name, camera_id, prior_q=np.zeros(4), prior_t=np.zeros(3)):\n",
    "\n",
    "        cursor = self.execute(\n",
    "            'INSERT INTO images VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)',\n",
    "            (\n",
    "                image_id,\n",
    "                name,\n",
    "                camera_id,\n",
    "                prior_q[0],\n",
    "                prior_q[1],\n",
    "                prior_q[2],\n",
    "                prior_q[3],\n",
    "                prior_t[0],\n",
    "                prior_t[1],\n",
    "                prior_t[2]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return cursor.lastrowid\n",
    "\n",
    "    def add_descriptors(self, image_id, descriptors):\n",
    "\n",
    "        descriptors = np.ascontiguousarray(descriptors, np.uint8)\n",
    "\n",
    "        self.execute(\n",
    "            'INSERT INTO descriptors VALUES (?, ?, ?, ?)',\n",
    "            (\n",
    "                    image_id,\n",
    "                    descriptors.shape[0],\n",
    "                    descriptors.shape[1],\n",
    "                    array_to_blob(descriptors)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def add_keypoints(self, image_id, keypoints):\n",
    "\n",
    "        keypoints = np.asarray(keypoints, np.float32)\n",
    "\n",
    "        self.execute(\n",
    "            'INSERT INTO keypoints VALUES (?, ?, ?, ?)',\n",
    "            (\n",
    "                image_id,\n",
    "                keypoints.shape[0],\n",
    "                keypoints.shape[1],\n",
    "                array_to_blob(keypoints)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def add_matches(self, image1_id, image2_id, matches):\n",
    "\n",
    "        if image1_id > image2_id:\n",
    "            matches = matches[:, ::-1]\n",
    "\n",
    "        pair_id = image_ids_to_pair_id(image1_id, image2_id)\n",
    "        matches = np.asarray(matches, np.uint32)\n",
    "\n",
    "        self.execute(\n",
    "            'INSERT INTO matches VALUES (?, ?, ?, ?)',\n",
    "            (\n",
    "                pair_id,\n",
    "                matches.shape[0],\n",
    "                matches.shape[1],\n",
    "                array_to_blob(matches)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def add_two_view_geometries(self, image1_id, image2_id, matches, config=2, F=np.eye(3), E=np.eye(3), H=np.eye(3)):\n",
    "\n",
    "        if image1_id > image2_id:\n",
    "            matches = matches[:, ::-1]\n",
    "\n",
    "        pair_id = image_ids_to_pair_id(image1_id, image2_id)\n",
    "        matches = np.asarray(matches, np.uint32)\n",
    "\n",
    "        F = np.asarray(F, dtype=np.float64)\n",
    "        E = np.asarray(E, dtype=np.float64)\n",
    "        H = np.asarray(H, dtype=np.float64)\n",
    "\n",
    "        self.execute(\n",
    "            'INSERT INTO two_view_geometries VALUES (?, ?, ?, ?, ?, ?, ?, ?)',\n",
    "            (\n",
    "                pair_id,\n",
    "                matches.shape[0],\n",
    "                matches.shape[1],\n",
    "                array_to_blob(matches),\n",
    "                config,\n",
    "                array_to_blob(F),\n",
    "                array_to_blob(E),\n",
    "                array_to_blob(H)\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def get_first_indices(x, dim=0):\n",
    "\n",
    "    \"\"\"\n",
    "    Get indices where values appear first\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: torch.Tensor\n",
    "        N-dimensional torch tensor\n",
    "\n",
    "    dim: int\n",
    "        Dimension of the unique operation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    first_indices: torch.Tensor\n",
    "        Indices where values appear first\n",
    "    \"\"\"\n",
    "\n",
    "    _, idx, counts = torch.unique(x, dim=dim, sorted=True, return_inverse=True, return_counts=True)\n",
    "    _, sorted_idx = torch.sort(idx, stable=True)\n",
    "    counts_cumsum = counts.cumsum(0)\n",
    "    counts_cumsum = torch.cat((torch.tensor([0], device=counts_cumsum.device), counts_cumsum[:-1]))\n",
    "    first_indices = sorted_idx[counts_cumsum]\n",
    "\n",
    "    return first_indices\n",
    "\n",
    "\n",
    "def write_matches(image_paths, image_pair_indices, first_image_keypoints, second_image_keypoints, output_directory):\n",
    "\n",
    "    \"\"\"\n",
    "    Write matches as h5 datasets for COLMAP\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_paths: list of shape (n_images)\n",
    "        List of image paths\n",
    "\n",
    "    image_pair_indices: list of shape (n_image_pairs)\n",
    "        List of tuples of image pair indices\n",
    "\n",
    "    first_image_keypoints: list of shape (n_image_pairs)\n",
    "        List of first image keypoints\n",
    "\n",
    "    second_image_keypoints: list of shape (n_image_pairs)\n",
    "        List of second image keypoints\n",
    "\n",
    "    output_directory: str or pathlib.Path object\n",
    "        Path of the output directory\n",
    "    \"\"\"\n",
    "\n",
    "    with h5py.File(output_directory / 'loftr_matches.h5', mode='w') as f:\n",
    "        for matching_index, image_pair_index in enumerate(image_pair_indices):\n",
    "            first_image_path, second_image_path = image_paths[image_pair_index[0]], image_paths[image_pair_index[1]]\n",
    "            first_image_filename, second_image_filename = first_image_path.split('/')[-1], second_image_path.split('/')[-1]\n",
    "\n",
    "            # Concatenate matched keypoints of an image pair and write it as a dataset\n",
    "            group = f.require_group(first_image_filename)\n",
    "            group.create_dataset(\n",
    "                second_image_filename,\n",
    "                data=np.concatenate([first_image_keypoints[matching_index], second_image_keypoints[matching_index]], axis=1)\n",
    "            )\n",
    "\n",
    "    keypoints = defaultdict(list)\n",
    "    match_indices = defaultdict(dict)\n",
    "    total_keypoints = defaultdict(int)\n",
    "\n",
    "    with h5py.File(output_directory / 'loftr_matches.h5', mode='r') as f:\n",
    "        for first_image_filename in f.keys():\n",
    "            group = f[first_image_filename]\n",
    "            for second_image_filename in group.keys():\n",
    "\n",
    "                image_pair_keypoints = group[second_image_filename][...]\n",
    "                keypoints[first_image_filename].append(image_pair_keypoints[:, :2])\n",
    "                keypoints[second_image_filename].append(image_pair_keypoints[:, 2:])\n",
    "                current_match = torch.arange(len(image_pair_keypoints)).reshape(-1, 1).repeat(1, 2)\n",
    "                current_match[:, 0] += total_keypoints[first_image_filename]\n",
    "                current_match[:, 1] += total_keypoints[second_image_filename]\n",
    "                total_keypoints[first_image_filename] += len(image_pair_keypoints)\n",
    "                total_keypoints[second_image_filename] += len(image_pair_keypoints)\n",
    "                match_indices[first_image_filename][second_image_filename] = current_match\n",
    "\n",
    "    for image_filename in keypoints.keys():\n",
    "        keypoints[image_filename] = np.round(np.concatenate(keypoints[image_filename], axis=0))\n",
    "\n",
    "    unique_keypoints = {}\n",
    "    unique_match_indices = {}\n",
    "    matches = defaultdict(dict)\n",
    "\n",
    "    for image_filename in keypoints.keys():\n",
    "        unique_keypoint_values, unique_keypoint_reverse_idx = torch.unique(torch.from_numpy(keypoints[image_filename]), dim=0, return_inverse=True)\n",
    "        unique_match_indices[image_filename] = unique_keypoint_reverse_idx\n",
    "        unique_keypoints[image_filename] = unique_keypoint_values.numpy()\n",
    "\n",
    "    for first_image_filename, group in match_indices.items():\n",
    "        for second_image_filename, image_pair_match_index in group.items():\n",
    "            image_pair_match_index_copy = deepcopy(image_pair_match_index)\n",
    "            image_pair_match_index_copy[:, 0] = unique_match_indices[first_image_filename][image_pair_match_index_copy[:, 0]]\n",
    "            image_pair_match_index_copy[:, 1] = unique_match_indices[second_image_filename][image_pair_match_index_copy[:, 1]]\n",
    "            matched_keypoints = np.concatenate([\n",
    "                unique_keypoints[first_image_filename][image_pair_match_index_copy[:, 0]].reshape(-1, 2),\n",
    "                unique_keypoints[second_image_filename][image_pair_match_index_copy[:, 1]].reshape(-1, 2)\n",
    "            ], axis=1)\n",
    "\n",
    "            if matched_keypoints.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            current_unique_match_index = get_first_indices(torch.from_numpy(matched_keypoints), dim=0)\n",
    "            image_pair_match_index_copy_semiclean = image_pair_match_index_copy[current_unique_match_index]\n",
    "\n",
    "            current_unique_match_index1 = get_first_indices(image_pair_match_index_copy_semiclean[:, 0], dim=0)\n",
    "            image_pair_match_index_copy_semiclean = image_pair_match_index_copy_semiclean[current_unique_match_index1]\n",
    "\n",
    "            current_unique_match_index2 = get_first_indices(image_pair_match_index_copy_semiclean[:, 1], dim=0)\n",
    "            image_pair_match_index_copy_semiclean2 = image_pair_match_index_copy_semiclean[current_unique_match_index2]\n",
    "\n",
    "            matches[first_image_filename][second_image_filename] = image_pair_match_index_copy_semiclean2.numpy()\n",
    "\n",
    "    with h5py.File(output_directory / 'keypoints.h5', mode='w') as f:\n",
    "        for image_filename, keypoints in unique_keypoints.items():\n",
    "            f[image_filename] = keypoints\n",
    "\n",
    "    with h5py.File(output_directory / 'matches.h5', mode='w') as f:\n",
    "        for first_image_filename, first_image_matches in matches.items():\n",
    "            group = f.require_group(first_image_filename)\n",
    "            for second_image_filename, second_image_matches in first_image_matches.items():\n",
    "                group[second_image_filename] = second_image_matches\n",
    "\n",
    "\n",
    "def push_to_database(colmap_database, dataset_directory, image_directory, camera_model, single_camera):\n",
    "\n",
    "    \"\"\"\n",
    "    Push cameras, images, keypoints and matches to COLMAP database\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    colmap_database: COLMAPDatabase\n",
    "        COLMAP Database object\n",
    "\n",
    "    dataset_directory: str or pathlib.Path\n",
    "        Reconstruction directory\n",
    "\n",
    "    image_directory: str or pathlib.Path\n",
    "        Image directory\n",
    "\n",
    "    camera_model: str\n",
    "        Model of the camera\n",
    "\n",
    "    single_camera: bool\n",
    "        Whether there is one or multiple in cameras\n",
    "    \"\"\"\n",
    "\n",
    "    keypoints_dataset = h5py.File(dataset_directory / 'keypoints.h5', 'r')\n",
    "\n",
    "    camera_id = None\n",
    "    image_filename_to_id = {}\n",
    "\n",
    "    for image_filename in tqdm(list(keypoints_dataset.keys())):\n",
    "\n",
    "        keypoints = keypoints_dataset[image_filename][()]\n",
    "\n",
    "        if camera_id is None or not single_camera:\n",
    "\n",
    "            image = Image.open(str(image_directory / image_filename))\n",
    "            width, height = image.size\n",
    "\n",
    "            focal_length = get_focal_length(image_path=str(image_directory / image_filename))\n",
    "\n",
    "            if camera_model == 'simple-pinhole':\n",
    "                model = 0\n",
    "                params = np.array([focal_length, width / 2, height / 2])\n",
    "            elif camera_model == 'pinhole':\n",
    "                model = 1\n",
    "                params = np.array([focal_length, focal_length, width / 2, height / 2])\n",
    "            elif camera_model == 'simple-radial':\n",
    "                model = 2\n",
    "                params = np.array([focal_length, width / 2, height / 2, 0.1])\n",
    "            elif camera_model == 'opencv':\n",
    "                model = 4\n",
    "                params = np.array([focal_length, focal_length, width / 2, height / 2, 0., 0., 0., 0.])\n",
    "            else:\n",
    "                raise ValueError(f'Invalid camera model: {camera_model}')\n",
    "\n",
    "            camera_id = colmap_database.add_camera(\n",
    "                camera_id=None,\n",
    "                model=model,\n",
    "                width=width,\n",
    "                height=height,\n",
    "                params=params,\n",
    "                prior_focal_length=False\n",
    "            )\n",
    "\n",
    "        image_id = colmap_database.add_image(image_id=None, name=image_filename, camera_id=camera_id)\n",
    "        image_filename_to_id[image_filename] = image_id\n",
    "\n",
    "        colmap_database.add_keypoints(image_id=image_id, keypoints=keypoints)\n",
    "\n",
    "    matches_dataset = h5py.File(dataset_directory / 'matches.h5', 'r')\n",
    "\n",
    "    pairs = set()\n",
    "\n",
    "    for image1_filename in matches_dataset.keys():\n",
    "        group = matches_dataset[image1_filename]\n",
    "        for image2_filename in group.keys():\n",
    "\n",
    "            image1_id = image_filename_to_id[image1_filename]\n",
    "            image2_id = image_filename_to_id[image2_filename]\n",
    "            pair_id = image_ids_to_pair_id(image1_id=image1_id, image2_id=image2_id)\n",
    "            if pair_id in pairs:\n",
    "                continue\n",
    "\n",
    "            matches = group[image2_filename][()]\n",
    "            colmap_database.add_matches(image1_id, image2_id, matches)\n",
    "            pairs.add(pair_id)\n",
    "\n",
    "    colmap_database.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d21957f",
   "metadata": {
    "papermill": {
     "duration": 0.00909,
     "end_time": "2023-05-28T15:45:09.400684",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.391594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371efb83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:09.420777Z",
     "iopub.status.busy": "2023-05-28T15:45:09.420445Z",
     "iopub.status.idle": "2023-05-28T15:45:09.432768Z",
     "shell.execute_reply": "2023-05-28T15:45:09.431884Z"
    },
    "papermill": {
     "duration": 0.024895,
     "end_time": "2023-05-28T15:45:09.434758",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.409863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_paths, transforms=None):\n",
    "\n",
    "        self.image_paths = image_paths\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Get the length the dataset\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        length: int\n",
    "            Length of the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        \"\"\"\n",
    "        Get the idxth element in the dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx: int\n",
    "            Index of the sample (0 <= idx < length of the dataset)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image: torch.FloatTensor of shape (channel, height, width) or numpy.ndarray of shape (height, width, channel)\n",
    "            Image tensor or array\n",
    "        \"\"\"\n",
    "\n",
    "        image = cv2.imread(str(self.image_paths[idx]))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=np.array(image))['image'].float()\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "class ImagePairDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_paths, image_pair_indices, transforms):\n",
    "\n",
    "        self.image_paths = image_paths\n",
    "        self.image_pair_indices = image_pair_indices\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Get the length the dataset\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        length: int\n",
    "            Length of the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        return len(self.image_pair_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        \"\"\"\n",
    "        Get the idxth element in the dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx: int\n",
    "            Index of the sample (0 <= idx < length of the dataset)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image1: torch.FloatTensor of shape (channel, height, width)\n",
    "            First image tensor\n",
    "\n",
    "        image2: torch.FloatTensor of shape (channel, height, width)\n",
    "            Second image tensor\n",
    "        \"\"\"\n",
    "\n",
    "        image1 = get_image_tensor(\n",
    "            image_path_or_array=str(self.image_paths[self.image_pair_indices[idx][0]]),\n",
    "            resize_shape=self.transforms['resize_shape'],\n",
    "            resize_longest_edge=self.transforms['resize_longest_edge'],\n",
    "            scale=self.transforms['scale'],\n",
    "            grayscale=self.transforms['grayscale']\n",
    "        )\n",
    "\n",
    "        image2 = get_image_tensor(\n",
    "            image_path_or_array=str(self.image_paths[self.image_pair_indices[idx][1]]),\n",
    "            resize_shape=self.transforms['resize_shape'],\n",
    "            resize_longest_edge=self.transforms['resize_longest_edge'],\n",
    "            scale=self.transforms['scale'],\n",
    "            grayscale=self.transforms['grayscale']\n",
    "        )\n",
    "\n",
    "        return image1, image2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d0beb",
   "metadata": {
    "papermill": {
     "duration": 0.009016,
     "end_time": "2023-05-28T15:45:09.453046",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.444030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Image Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6eb5464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:09.473633Z",
     "iopub.status.busy": "2023-05-28T15:45:09.473025Z",
     "iopub.status.idle": "2023-05-28T15:45:09.491583Z",
     "shell.execute_reply": "2023-05-28T15:45:09.490720Z"
    },
    "papermill": {
     "duration": 0.031108,
     "end_time": "2023-05-28T15:45:09.493559",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.462451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_feature_extractor(model_name, pretrained, model_args):\n",
    "\n",
    "    \"\"\"\n",
    "    Load specified pretrained model for feature extraction\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name: str\n",
    "        Model name\n",
    "\n",
    "    pretrained: bool\n",
    "        Whether to load pretrained weights or not\n",
    "\n",
    "    model_args: dict\n",
    "        Dictionary of model keyword arguments\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model: torch.nn.Module\n",
    "        Model\n",
    "    \"\"\"\n",
    "\n",
    "    model = timm.create_model(\n",
    "        model_name=model_name,\n",
    "        pretrained=pretrained,\n",
    "        **model_args\n",
    "    )\n",
    "    # Override the head layer with Identity in transformer models so the output will be features\n",
    "    model.head = nn.Identity()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def extract_features(inputs, model, pooling_type, device, amp):\n",
    "\n",
    "    \"\"\"\n",
    "    Extract features from given inputs with given model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inputs: torch.FloatTensor of shape (batch, channel, height, width)\n",
    "        Inputs tensor\n",
    "\n",
    "    model: torch.nn.Module\n",
    "        Model\n",
    "\n",
    "    pooling_type: str\n",
    "        Pooling type applied to features\n",
    "\n",
    "    device: torch.device\n",
    "        Location of the inputs tensor and the model\n",
    "\n",
    "    amp: bool\n",
    "        Whether to use auto mixed precision or not\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features: torch.FloatTensor of shape (batch, features)\n",
    "        Features tensor\n",
    "    \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if amp:\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.bfloat16):\n",
    "                if pooling_type is not None:\n",
    "                    # Use forward features if pooling type is specified (convolutional models)\n",
    "                    features = model.forward_features(inputs)\n",
    "                else:\n",
    "                    # Use forward if pooling type is not specified (transformer models)\n",
    "                    features = model(inputs)\n",
    "        else:\n",
    "            if pooling_type is not None:\n",
    "                features = model.forward_features(inputs)\n",
    "            else:\n",
    "                features = model(inputs)\n",
    "\n",
    "    features = features.detach().cpu()\n",
    "\n",
    "    if pooling_type == 'avg':\n",
    "        features = F.adaptive_avg_pool2d(features, output_size=(1, 1)).view(features.size(0), -1)\n",
    "    elif pooling_type == 'max':\n",
    "        features = F.adaptive_max_pool2d(features, output_size=(1, 1)).view(features.size(0), -1)\n",
    "    elif pooling_type == 'concat':\n",
    "        features = torch.cat([\n",
    "            F.adaptive_avg_pool2d(features, output_size=(1, 1)).view(features.size(0), -1),\n",
    "            F.adaptive_max_pool2d(features, output_size=(1, 1)).view(features.size(0), -1)\n",
    "        ], dim=-1)\n",
    "\n",
    "    features = features / features.norm(dim=1).view(-1, 1)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def select_images(image_paths, image_selection_features, image_count):\n",
    "\n",
    "    \"\"\"\n",
    "    Select most similar images\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_paths: list of shape (n_images)\n",
    "        List of image paths\n",
    "\n",
    "    image_selection_features: np.ndarray of shape (n_images, n_features)\n",
    "        Features array\n",
    "\n",
    "    image_count: int\n",
    "        Image count to retrieve most similar images\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image_paths: list of shape (image_count)\n",
    "        List of most similar image paths\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate pairwise cosine similarities between features\n",
    "    pairwise_cosine_similarities = cosine_similarity(image_selection_features)\n",
    "\n",
    "    # Zero the diagonal and calculate mean cosine similarities\n",
    "    np.fill_diagonal(pairwise_cosine_similarities, 0)\n",
    "    mean_cosine_similarities = pairwise_cosine_similarities.mean(axis=1)\n",
    "\n",
    "    # Extract sorting index in descending order\n",
    "    sorting_idx = np.argsort(mean_cosine_similarities)[::-1]\n",
    "\n",
    "    image_paths = np.array(image_paths)\n",
    "    image_paths = image_paths[sorting_idx][:image_count].tolist()\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "\n",
    "def prepare_dataloader(image_paths, transforms, batch_size, num_workers):\n",
    "\n",
    "    \"\"\"\n",
    "    Prepare data loader for inference\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_paths: list of shape (n_images)\n",
    "        List of image paths\n",
    "\n",
    "    transforms: dict\n",
    "        Transform pipeline\n",
    "\n",
    "    batch_size: int\n",
    "        Batch size of the data loader\n",
    "\n",
    "    num_workers: int\n",
    "        Number of workers of the data loader\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_loader: torch.utils.data.DataLoader\n",
    "        Data loader\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = ImageDataset(image_paths=image_paths, transforms=transforms)\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=SequentialSampler(dataset),\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "def create_image_selection_transforms(**transform_parameters):\n",
    "\n",
    "    \"\"\"\n",
    "    Create transformation pipeline for image selection\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transform_parameters: dict\n",
    "        Dictionary of transform parameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    transforms: dict\n",
    "        Transform pipeline for image selection\n",
    "    \"\"\"\n",
    "\n",
    "    image_selection_transforms = A.Compose([\n",
    "        A.Resize(\n",
    "            height=transform_parameters['resize_height'],\n",
    "            width=transform_parameters['resize_width'],\n",
    "            interpolation=cv2.INTER_NEAREST,\n",
    "            always_apply=True\n",
    "        ),\n",
    "        A.Normalize(\n",
    "            mean=transform_parameters['normalize_mean'],\n",
    "            std=transform_parameters['normalize_std'],\n",
    "            max_pixel_value=transform_parameters['normalize_max_pixel_value'],\n",
    "            always_apply=True\n",
    "        ),\n",
    "        ToTensorV2(always_apply=True)\n",
    "    ])\n",
    "\n",
    "    return image_selection_transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c2fb3c",
   "metadata": {
    "papermill": {
     "duration": 0.008933,
     "end_time": "2023-05-28T15:45:09.511665",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.502732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. LoFTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb2b9969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:09.531532Z",
     "iopub.status.busy": "2023-05-28T15:45:09.531241Z",
     "iopub.status.idle": "2023-05-28T15:45:09.542403Z",
     "shell.execute_reply": "2023-05-28T15:45:09.541578Z"
    },
    "papermill": {
     "duration": 0.023557,
     "end_time": "2023-05-28T15:45:09.544320",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.520763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loftr_match_images(image1, image2, model, device, amp, transforms):\n",
    "\n",
    "    \"\"\"\n",
    "    Match given two images with each other using LoFTR model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image1: numpy.ndarray of shape (3, height, width)\n",
    "        Batch of first images tensor\n",
    "\n",
    "    image2: numpy.ndarray of shape (3, height, width)\n",
    "        Batch of second images tensor\n",
    "\n",
    "    model: torch.nn.Module\n",
    "        LoFTR Model\n",
    "\n",
    "    device: torch.device\n",
    "        Location of the image1, image2 and the model\n",
    "\n",
    "    amp: bool\n",
    "        Whether to use auto mixed precision or not\n",
    "\n",
    "    transforms: dict\n",
    "        Dictionary of transform parameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    outputs: dict\n",
    "        Model outputs\n",
    "    \"\"\"\n",
    "\n",
    "    image1_raw_height, image1_raw_width = image1.shape[:2]\n",
    "    image1 = get_image_tensor(\n",
    "        image_path_or_array=image1,\n",
    "        resize_shape=transforms['resize_shape'],\n",
    "        resize_longest_edge=transforms['resize_longest_edge'],\n",
    "        scale=transforms['scale'],\n",
    "        grayscale=transforms['grayscale']\n",
    "    )\n",
    "    image1 = image1.to(device)\n",
    "    image1_transformed_height, image1_transformed_width = image1.shape[2:]\n",
    "\n",
    "    image2_raw_height, image2_raw_width = image2.shape[:2]\n",
    "    image2 = get_image_tensor(\n",
    "        image_path_or_array=image2,\n",
    "        resize_shape=transforms['resize_shape'],\n",
    "        resize_longest_edge=transforms['resize_longest_edge'],\n",
    "        scale=transforms['scale'],\n",
    "        grayscale=transforms['grayscale']\n",
    "    )\n",
    "    image2 = image2.to(device)\n",
    "    image2_transformed_height, image2_transformed_width = image2.shape[2:]\n",
    "\n",
    "    inputs = {\n",
    "        'image0': image1,\n",
    "        'image1': image2\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if amp:\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.float16):\n",
    "                outputs = model(inputs)\n",
    "        else:\n",
    "            outputs = model(inputs)\n",
    "\n",
    "    outputs = {\n",
    "        'keypoints0': outputs['keypoints0'].detach().cpu().numpy(),\n",
    "        'keypoints1': outputs['keypoints1'].detach().cpu().numpy(),\n",
    "        'confidence': outputs['confidence'].detach().cpu().numpy(),\n",
    "        'batch_indexes': outputs['batch_indexes'].detach().cpu().numpy()\n",
    "    }\n",
    "\n",
    "    outputs['keypoints0'][:, 0] *= image1_raw_width / image1_transformed_width\n",
    "    outputs['keypoints0'][:, 1] *= image1_raw_height / image1_transformed_height\n",
    "    outputs['keypoints1'][:, 0] *= image2_raw_width / image2_transformed_width\n",
    "    outputs['keypoints1'][:, 1] *= image2_raw_height / image2_transformed_height\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e61fd89",
   "metadata": {
    "papermill": {
     "duration": 0.008897,
     "end_time": "2023-05-28T15:45:09.562299",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.553402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. SuperGlue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ee5c929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:09.582263Z",
     "iopub.status.busy": "2023-05-28T15:45:09.581987Z",
     "iopub.status.idle": "2023-05-28T15:45:09.596347Z",
     "shell.execute_reply": "2023-05-28T15:45:09.595511Z"
    },
    "papermill": {
     "duration": 0.027069,
     "end_time": "2023-05-28T15:45:09.598539",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.571470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def superglue_match_images(image1, image2, model, device, amp, transforms):\n",
    "\n",
    "    \"\"\"\n",
    "    Match given two images with each other using SuperGlue model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image1: numpy.ndarray of shape (3, height, width)\n",
    "        Batch of first images tensor\n",
    "\n",
    "    image2: numpy.ndarray of shape (3, height, width)\n",
    "        Batch of second images tensor\n",
    "\n",
    "    model: torch.nn.Module\n",
    "        SuperGlue Model\n",
    "\n",
    "    device: torch.device\n",
    "        Location of the image1, image2 and the model\n",
    "\n",
    "    amp: bool\n",
    "        Whether to use auto mixed precision or not\n",
    "\n",
    "    transforms: dict\n",
    "        Dictionary of transform parameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    outputs: dict\n",
    "        Model outputs\n",
    "    \"\"\"\n",
    "\n",
    "    image1_raw_height, image1_raw_width = image1.shape[:2]\n",
    "    image1 = get_image_tensor(\n",
    "        image_path_or_array=image1,\n",
    "        resize=transforms['resize'],\n",
    "        resize_shape=transforms['resize_shape'],\n",
    "        resize_longest_edge=transforms['resize_longest_edge'],\n",
    "        scale=transforms['scale'],\n",
    "        grayscale=transforms['grayscale']\n",
    "    )\n",
    "    image1 = image1.to(device)\n",
    "    image1_transformed_height, image1_transformed_width = image1.shape[2:]\n",
    "\n",
    "    image2_raw_height, image2_raw_width = image2.shape[:2]\n",
    "    image2 = get_image_tensor(\n",
    "        image_path_or_array=image2,\n",
    "        resize=transforms['resize'],\n",
    "        resize_shape=transforms['resize_shape'],\n",
    "        resize_longest_edge=transforms['resize_longest_edge'],\n",
    "        scale=transforms['scale'],\n",
    "        grayscale=transforms['grayscale']\n",
    "    )\n",
    "    image2 = image2.to(device)\n",
    "    image2_transformed_height, image2_transformed_width = image2.shape[2:]\n",
    "\n",
    "    inputs = {\n",
    "        'image0': image1,\n",
    "        'image1': image2\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if amp:\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.float16):\n",
    "                outputs = model(inputs)\n",
    "        else:\n",
    "            outputs = model(inputs)\n",
    "\n",
    "    outputs = {\n",
    "        'keypoints0': outputs['keypoints0'][0].detach().cpu().numpy(),\n",
    "        'scores0': outputs['scores0'][0].detach().cpu().numpy(),\n",
    "        'descriptors0': outputs['descriptors0'][0].detach().cpu().numpy().T,\n",
    "        'keypoints1': outputs['keypoints1'][0].detach().cpu().numpy(),\n",
    "        'scores1': outputs['scores1'][0].detach().cpu().numpy(),\n",
    "        'descriptors1': outputs['descriptors1'][0].detach().cpu().numpy().T,\n",
    "        'matches0': outputs['matches0'][0].detach().cpu().numpy(),\n",
    "        'matches1': outputs['matches1'][0].detach().cpu().numpy(),\n",
    "        'matching_scores0': outputs['matching_scores0'][0].detach().cpu().numpy(),\n",
    "        'matching_scores1': outputs['matching_scores1'][0].detach().cpu().numpy(),\n",
    "    }\n",
    "\n",
    "    matches_mask = outputs['matches0'] > -1\n",
    "\n",
    "    for k in ['keypoints1', 'scores1', 'descriptors1', 'matches1', 'matching_scores1']:\n",
    "        outputs[k] = outputs[k][outputs['matches0'][matches_mask]]\n",
    "\n",
    "    for k in ['keypoints0', 'scores0', 'descriptors0', 'matches0', 'matching_scores0']:\n",
    "        outputs[k] = outputs[k][matches_mask]\n",
    "\n",
    "    outputs['keypoints0'][:, 0] *= image1_raw_width / image1_transformed_width\n",
    "    outputs['keypoints0'][:, 1] *= image1_raw_height / image1_transformed_height\n",
    "    outputs['keypoints1'][:, 0] *= image2_raw_width / image2_transformed_width\n",
    "    outputs['keypoints1'][:, 1] *= image2_raw_height / image2_transformed_height\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e582131",
   "metadata": {
    "papermill": {
     "duration": 0.008873,
     "end_time": "2023-05-28T15:45:09.616418",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.607545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8498ceb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:09.636028Z",
     "iopub.status.busy": "2023-05-28T15:45:09.635769Z",
     "iopub.status.idle": "2023-05-28T15:45:09.643382Z",
     "shell.execute_reply": "2023-05-28T15:45:09.642476Z"
    },
    "papermill": {
     "duration": 0.01981,
     "end_time": "2023-05-28T15:45:09.645298",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.625488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./config.yaml\n",
    "\n",
    "dataset:\n",
    "  haiper:\n",
    "    bike:\n",
    "      image_directory: images\n",
    "    chairs:\n",
    "      image_directory: images\n",
    "    fountain:\n",
    "      image_directory: images\n",
    "  heritage:\n",
    "    dioscuri:\n",
    "      image_directory: images\n",
    "    cyprus:\n",
    "      image_directory: images\n",
    "    wall:\n",
    "      image_directory: images\n",
    "  urban:\n",
    "   kyiv-puppet-theater:\n",
    "     image_directory: images\n",
    "\n",
    "image_selection:\n",
    "  image_count: 200\n",
    "  criteria: step_size\n",
    "  model:\n",
    "    model_name: convnext_base\n",
    "    pretrained: True\n",
    "    model_args: {}\n",
    "  transforms:\n",
    "    resize_height: 512\n",
    "    resize_width: 512\n",
    "    normalize_mean: [0.485, 0.456, 0.406]\n",
    "    normalize_std: [0.229, 0.224, 0.225]\n",
    "    normalize_max_pixel_value: 255\n",
    "  pooling_type: avg\n",
    "  amp: False\n",
    "  batch_size: 16\n",
    "  num_workers: 2\n",
    "  device: cuda\n",
    "\n",
    "loftr:\n",
    "  pretrained: null\n",
    "  pretrained_weights_path: /kaggle/input/image-matching-challenge-2023-dataset/models/loftr/loftr_outdoor.ckpt\n",
    "  transforms:\n",
    "    resize_shape: 840\n",
    "    resize_longest_edge: True\n",
    "    scale: True\n",
    "    grayscale: True\n",
    "\n",
    "superglue:\n",
    "  superpoint:\n",
    "    descriptor_dim: 256\n",
    "    nms_radius: 4\n",
    "    keypoint_threshold: 0.01\n",
    "    max_keypoints: -1\n",
    "    remove_borders: 4\n",
    "  superglue:\n",
    "    descriptor_dim: 256\n",
    "    weights: outdoor\n",
    "    keypoint_encoder: [32, 64, 128, 256]\n",
    "    sinkhorn_iterations: 100\n",
    "    match_threshold: 0.2\n",
    "  transforms:\n",
    "    resize: False\n",
    "    resize_shape: 1920\n",
    "    resize_longest_edge: True\n",
    "    scale: True\n",
    "    grayscale: True\n",
    "\n",
    "image_matching:\n",
    "  amp: False\n",
    "  batch_size: 1\n",
    "  num_workers: 2\n",
    "  device: cuda\n",
    "\n",
    "colmap:\n",
    "  device: cpu\n",
    "\n",
    "sift_extraction:\n",
    "  num_threads: -1\n",
    "  max_image_size: 1400\n",
    "  max_num_features: 8192\n",
    "  first_octave: -1\n",
    "  num_octaves: 4\n",
    "  octave_resolution: 3\n",
    "  peak_threshold: 0.0066\n",
    "  edge_threshold: 10\n",
    "  estimate_affine_shape: False\n",
    "  max_num_orientations: 2\n",
    "  upright: False\n",
    "  darkness_adaptivity: False\n",
    "  domain_size_pooling: False\n",
    "  dsp_min_scale: 0.16\n",
    "  dsp_max_scale: 3\n",
    "  dsp_num_scales: 10\n",
    "  normalization: 'L2'\n",
    "\n",
    "sift_matching:\n",
    "  num_threads: -1\n",
    "  max_ratio: 0.9\n",
    "  max_distance: 0.7\n",
    "  cross_check: True\n",
    "  max_num_matches: 32768\n",
    "  max_error: 1.0\n",
    "  confidence: 0.9\n",
    "  min_num_trials: 100\n",
    "  max_num_trials: 10000\n",
    "  min_inlier_ratio: 0.25\n",
    "  min_num_inliers: 15\n",
    "  multiple_models: False\n",
    "  guided_matching: False\n",
    "  planar_scene: False\n",
    "\n",
    "exhaustive_matching:\n",
    "  block_size: 50\n",
    "\n",
    "incremental_mapper:\n",
    "  min_num_matches: 2\n",
    "  ignore_watermarks: False\n",
    "  multiple_models: True\n",
    "  max_num_models: 50\n",
    "  max_model_overlap: 20\n",
    "  min_model_size: 10\n",
    "  init_image_id1: -1\n",
    "  init_image_id2: -1\n",
    "  init_num_trials: 200\n",
    "  extract_colors: False\n",
    "  num_threads: -1\n",
    "  min_focal_length_ratio: 0.1\n",
    "  max_focal_length_ratio: 10.0\n",
    "  max_extra_param: 1.0\n",
    "  ba_refine_focal_length: True\n",
    "  ba_refine_principal_point: False\n",
    "  ba_refine_extra_params: True\n",
    "  ba_min_num_residuals_for_multi_threading: 50000\n",
    "  ba_local_num_images: 6\n",
    "  ba_local_function_tolerance: 0.0\n",
    "  ba_local_max_num_iterations: 25\n",
    "  ba_global_use_pba: False\n",
    "  ba_global_pba_gpu_index: -1\n",
    "  ba_global_images_ratio: 1.1\n",
    "  ba_global_points_ratio: 1.1\n",
    "  ba_global_images_freq: 500\n",
    "  ba_global_points_freq: 250000\n",
    "  ba_global_function_tolerance: 0.0\n",
    "  ba_global_max_num_iterations: 50\n",
    "  ba_local_max_refinements: 2\n",
    "  ba_local_max_refinement_change: 0.001\n",
    "  ba_global_max_refinements: 5\n",
    "  ba_global_max_refinement_change: 0.0005\n",
    "  fix_existing_images: False\n",
    "\n",
    "persistence:\n",
    "  root_directory: inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92881237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:09.665064Z",
     "iopub.status.busy": "2023-05-28T15:45:09.664345Z",
     "iopub.status.idle": "2023-05-28T15:45:09.695508Z",
     "shell.execute_reply": "2023-05-28T15:45:09.694673Z"
    },
    "papermill": {
     "duration": 0.04303,
     "end_time": "2023-05-28T15:45:09.697366",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.654336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'haiper': {'bike': {'image_directory': 'images'},\n",
       "   'chairs': {'image_directory': 'images'},\n",
       "   'fountain': {'image_directory': 'images'}},\n",
       "  'heritage': {'dioscuri': {'image_directory': 'images'},\n",
       "   'cyprus': {'image_directory': 'images'},\n",
       "   'wall': {'image_directory': 'images'}},\n",
       "  'urban': {'kyiv-puppet-theater': {'image_directory': 'images'}}},\n",
       " 'image_selection': {'image_count': 200,\n",
       "  'criteria': 'step_size',\n",
       "  'model': {'model_name': 'convnext_base',\n",
       "   'pretrained': True,\n",
       "   'model_args': {}},\n",
       "  'transforms': {'resize_height': 512,\n",
       "   'resize_width': 512,\n",
       "   'normalize_mean': [0.485, 0.456, 0.406],\n",
       "   'normalize_std': [0.229, 0.224, 0.225],\n",
       "   'normalize_max_pixel_value': 255},\n",
       "  'pooling_type': 'avg',\n",
       "  'amp': False,\n",
       "  'batch_size': 16,\n",
       "  'num_workers': 2,\n",
       "  'device': 'cuda'},\n",
       " 'loftr': {'pretrained': None,\n",
       "  'pretrained_weights_path': '/kaggle/input/image-matching-challenge-2023-dataset/models/loftr/loftr_outdoor.ckpt',\n",
       "  'transforms': {'resize_shape': 840,\n",
       "   'resize_longest_edge': True,\n",
       "   'scale': True,\n",
       "   'grayscale': True}},\n",
       " 'superglue': {'superpoint': {'descriptor_dim': 256,\n",
       "   'nms_radius': 4,\n",
       "   'keypoint_threshold': 0.01,\n",
       "   'max_keypoints': -1,\n",
       "   'remove_borders': 4},\n",
       "  'superglue': {'descriptor_dim': 256,\n",
       "   'weights': 'outdoor',\n",
       "   'keypoint_encoder': [32, 64, 128, 256],\n",
       "   'sinkhorn_iterations': 100,\n",
       "   'match_threshold': 0.2},\n",
       "  'transforms': {'resize': False,\n",
       "   'resize_shape': 1920,\n",
       "   'resize_longest_edge': True,\n",
       "   'scale': True,\n",
       "   'grayscale': True}},\n",
       " 'image_matching': {'amp': False,\n",
       "  'batch_size': 1,\n",
       "  'num_workers': 2,\n",
       "  'device': 'cuda'},\n",
       " 'colmap': {'device': 'cpu'},\n",
       " 'sift_extraction': {'num_threads': -1,\n",
       "  'max_image_size': 1400,\n",
       "  'max_num_features': 8192,\n",
       "  'first_octave': -1,\n",
       "  'num_octaves': 4,\n",
       "  'octave_resolution': 3,\n",
       "  'peak_threshold': 0.0066,\n",
       "  'edge_threshold': 10,\n",
       "  'estimate_affine_shape': False,\n",
       "  'max_num_orientations': 2,\n",
       "  'upright': False,\n",
       "  'darkness_adaptivity': False,\n",
       "  'domain_size_pooling': False,\n",
       "  'dsp_min_scale': 0.16,\n",
       "  'dsp_max_scale': 3,\n",
       "  'dsp_num_scales': 10,\n",
       "  'normalization': 'L2'},\n",
       " 'sift_matching': {'num_threads': -1,\n",
       "  'max_ratio': 0.9,\n",
       "  'max_distance': 0.7,\n",
       "  'cross_check': True,\n",
       "  'max_num_matches': 32768,\n",
       "  'max_error': 1.0,\n",
       "  'confidence': 0.9,\n",
       "  'min_num_trials': 100,\n",
       "  'max_num_trials': 10000,\n",
       "  'min_inlier_ratio': 0.25,\n",
       "  'min_num_inliers': 15,\n",
       "  'multiple_models': False,\n",
       "  'guided_matching': False,\n",
       "  'planar_scene': False},\n",
       " 'exhaustive_matching': {'block_size': 50},\n",
       " 'incremental_mapper': {'min_num_matches': 2,\n",
       "  'ignore_watermarks': False,\n",
       "  'multiple_models': True,\n",
       "  'max_num_models': 50,\n",
       "  'max_model_overlap': 20,\n",
       "  'min_model_size': 10,\n",
       "  'init_image_id1': -1,\n",
       "  'init_image_id2': -1,\n",
       "  'init_num_trials': 200,\n",
       "  'extract_colors': False,\n",
       "  'num_threads': -1,\n",
       "  'min_focal_length_ratio': 0.1,\n",
       "  'max_focal_length_ratio': 10.0,\n",
       "  'max_extra_param': 1.0,\n",
       "  'ba_refine_focal_length': True,\n",
       "  'ba_refine_principal_point': False,\n",
       "  'ba_refine_extra_params': True,\n",
       "  'ba_min_num_residuals_for_multi_threading': 50000,\n",
       "  'ba_local_num_images': 6,\n",
       "  'ba_local_function_tolerance': 0.0,\n",
       "  'ba_local_max_num_iterations': 25,\n",
       "  'ba_global_use_pba': False,\n",
       "  'ba_global_pba_gpu_index': -1,\n",
       "  'ba_global_images_ratio': 1.1,\n",
       "  'ba_global_points_ratio': 1.1,\n",
       "  'ba_global_images_freq': 500,\n",
       "  'ba_global_points_freq': 250000,\n",
       "  'ba_global_function_tolerance': 0.0,\n",
       "  'ba_global_max_num_iterations': 50,\n",
       "  'ba_local_max_refinements': 2,\n",
       "  'ba_local_max_refinement_change': 0.001,\n",
       "  'ba_global_max_refinements': 5,\n",
       "  'ba_global_max_refinement_change': 0.0005,\n",
       "  'fix_existing_images': False},\n",
       " 'persistence': {'root_directory': 'inference'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = yaml.load(open('config.yaml', 'r'), Loader=yaml.FullLoader)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac781bec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:09.718191Z",
     "iopub.status.busy": "2023-05-28T15:45:09.717421Z",
     "iopub.status.idle": "2023-05-28T15:45:17.300988Z",
     "shell.execute_reply": "2023-05-28T15:45:17.299543Z"
    },
    "papermill": {
     "duration": 7.596431,
     "end_time": "2023-05-28T15:45:17.303345",
     "exception": false,
     "start_time": "2023-05-28T15:45:09.706914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n"
     ]
    }
   ],
   "source": [
    "image_matching_device = torch.device(config['image_matching']['device'])\n",
    "\n",
    "# Load LoFTR model with specified configurations\n",
    "loftr_model = LoFTR(config['loftr']['pretrained'])\n",
    "loftr_model.load_state_dict(torch.load(config['loftr']['pretrained_weights_path'])['state_dict'])\n",
    "loftr_model = loftr_model.eval().to(image_matching_device)\n",
    "loftr_transforms = config['loftr']['transforms']\n",
    "\n",
    "# Load SuperPoint and SuperGlue model with specified configurations\n",
    "superglue_model = Matching(config['superglue'])\n",
    "superglue_model = superglue_model.eval().to(image_matching_device)\n",
    "superglue_transforms = config['superglue']['transforms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba77ee78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:45:17.324986Z",
     "iopub.status.busy": "2023-05-28T15:45:17.324690Z",
     "iopub.status.idle": "2023-05-28T15:47:47.048951Z",
     "shell.execute_reply": "2023-05-28T15:47:47.046926Z"
    },
    "papermill": {
     "duration": 149.73803,
     "end_time": "2023-05-28T15:47:47.051455",
     "exception": false,
     "start_time": "2023-05-28T15:45:17.313425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [02:14<00:00,  1.28s/it]\n",
      "100%|██████████| 15/15 [00:00<00:00, 1216.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================================\n",
      "Exhaustive feature matching\n",
      "==============================================================================\n",
      "\n",
      "Matching block [1/1, 1/1] in 9.871s\n",
      "Elapsed time: 0.165 [minutes]\n",
      "\n",
      "==============================================================================\n",
      "Loading database\n",
      "==============================================================================\n",
      "\n",
      "Loading cameras... 1 in 0.000s\n",
      "Loading matches... 45 in 0.000s\n",
      "Loading images... 15 in 0.002s (connected 15)\n",
      "Building correspondence graph... in 0.002s (ignored 0)\n",
      "\n",
      "Elapsed time: 0.000 [minutes]\n",
      "\n",
      "\n",
      "==============================================================================\n",
      "Finding good initial image pair\n",
      "==============================================================================\n",
      "\n",
      "\n",
      "==============================================================================\n",
      "Initializing with image pair #7 and #1\n",
      "==============================================================================\n",
      "\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  5.438185e+03    0.00e+00    1.72e+05   0.00e+00   0.00e+00  1.00e+04        0    3.49e-03    1.33e-02\n",
      "   1  3.298348e+03    2.14e+03    6.14e+05   1.45e+01   8.35e-01  1.43e+04        1    6.50e-03    1.98e-02\n",
      "   2  2.951298e+03    3.47e+02    1.37e+05   3.04e+01   7.44e-01  1.62e+04        1    3.16e-03    2.30e-02\n",
      "   3  2.940719e+03    1.06e+01    1.92e+05   3.37e+01   4.80e-02  9.32e+03        1    3.11e-03    2.61e-02\n",
      "   4  2.693774e+03    2.47e+02    7.27e+04   1.85e+01   9.07e-01  2.03e+04        1    3.11e-03    2.92e-02\n",
      "   5  3.065484e+03   -3.72e+02    7.27e+04   4.09e+01  -2.34e+00  1.01e+04        1    1.48e-03    3.08e-02\n",
      "   6  2.635922e+03    5.79e+01    8.28e+04   2.06e+01   6.17e-01  1.03e+04        1    3.02e-03    3.38e-02\n",
      "   7  2.568635e+03    6.73e+01    8.51e+04   2.08e+01   6.29e-01  1.04e+04        1    3.11e-03    3.69e-02\n",
      "   8  2.499495e+03    6.91e+01    8.79e+04   2.11e+01   6.08e-01  1.05e+04        1    3.08e-03    4.01e-02\n",
      "   9  2.427064e+03    7.24e+01    8.95e+04   2.13e+01   5.99e-01  1.06e+04        1    3.15e-03    4.32e-02\n",
      "  10  2.352106e+03    7.50e+01    9.05e+04   2.14e+01   5.89e-01  1.07e+04        1    3.18e-03    4.64e-02\n",
      "  11  2.274775e+03    7.73e+01    9.09e+04   2.14e+01   5.81e-01  1.07e+04        1    3.11e-03    4.96e-02\n",
      "  12  2.195288e+03    7.95e+01    9.09e+04   2.14e+01   5.75e-01  1.08e+04        1    3.09e-03    5.27e-02\n",
      "  13  2.113831e+03    8.15e+01    9.05e+04   2.13e+01   5.69e-01  1.08e+04        1    3.32e-03    5.60e-02\n",
      "  14  2.030590e+03    8.32e+01    8.97e+04   2.12e+01   5.65e-01  1.08e+04        1    3.24e-03    5.93e-02\n",
      "  15  1.945757e+03    8.48e+01    8.85e+04   2.10e+01   5.62e-01  1.08e+04        1    3.15e-03    6.25e-02\n",
      "  16  1.859545e+03    8.62e+01    8.70e+04   2.09e+01   5.59e-01  1.09e+04        1    3.10e-03    6.56e-02\n",
      "  17  1.772187e+03    8.74e+01    8.52e+04   2.06e+01   5.58e-01  1.09e+04        1    3.10e-03    6.87e-02\n",
      "  18  1.683950e+03    8.82e+01    8.36e+04   2.04e+01   5.58e-01  1.09e+04        1    3.08e-03    7.18e-02\n",
      "  19  1.595130e+03    8.88e+01    8.23e+04   2.01e+01   5.60e-01  1.09e+04        1    3.24e-03    7.51e-02\n",
      "  20  1.506063e+03    8.91e+01    8.07e+04   1.97e+01   5.62e-01  1.09e+04        1    3.09e-03    7.82e-02\n",
      "  21  1.417121e+03    8.89e+01    7.88e+04   1.93e+01   5.65e-01  1.10e+04        1    3.11e-03    8.13e-02\n",
      "  22  1.328709e+03    8.84e+01    7.65e+04   1.89e+01   5.70e-01  1.10e+04        1    3.13e-03    8.45e-02\n",
      "  23  1.241262e+03    8.74e+01    7.39e+04   1.85e+01   5.75e-01  1.10e+04        1    3.17e-03    8.77e-02\n",
      "  24  1.155233e+03    8.60e+01    7.11e+04   1.80e+01   5.82e-01  1.11e+04        1    3.09e-03    9.08e-02\n",
      "  25  1.071082e+03    8.42e+01    6.81e+04   1.75e+01   5.89e-01  1.11e+04        1    3.19e-03    9.40e-02\n",
      "  26  9.892566e+02    8.18e+01    6.49e+04   1.70e+01   5.97e-01  1.12e+04        1    3.16e-03    9.72e-02\n",
      "  27  9.101776e+02    7.91e+01    6.16e+04   1.64e+01   6.05e-01  1.13e+04        1    3.18e-03    1.00e-01\n",
      "  28  8.342241e+02    7.60e+01    5.82e+04   1.59e+01   6.14e-01  1.15e+04        1    3.21e-03    1.04e-01\n",
      "  29  7.617220e+02    7.25e+01    5.49e+04   1.53e+01   6.22e-01  1.16e+04        1    3.12e-03    1.07e-01\n",
      "  30  6.929395e+02    6.88e+01    5.16e+04   1.48e+01   6.31e-01  1.18e+04        1    3.10e-03    1.10e-01\n",
      "  31  6.280868e+02    6.49e+01    4.83e+04   1.42e+01   6.39e-01  1.21e+04        1    3.11e-03    1.13e-01\n",
      "  32  5.673211e+02    6.08e+01    4.52e+04   1.37e+01   6.47e-01  1.24e+04        1    3.25e-03    1.16e-01\n",
      "  33  5.107532e+02    5.66e+01    4.21e+04   1.32e+01   6.55e-01  1.28e+04        1    3.12e-03    1.19e-01\n",
      "  34  4.584543e+02    5.23e+01    3.91e+04   1.26e+01   6.62e-01  1.32e+04        1    3.14e-03    1.23e-01\n",
      "  35  4.104609e+02    4.80e+01    3.62e+04   1.21e+01   6.69e-01  1.38e+04        1    3.10e-03    1.26e-01\n",
      "  36  3.667779e+02    4.37e+01    3.34e+04   1.16e+01   6.77e-01  1.44e+04        1    3.09e-03    1.29e-01\n",
      "  37  3.273799e+02    3.94e+01    3.07e+04   1.11e+01   6.84e-01  1.52e+04        1    3.34e-03    1.32e-01\n",
      "  38  2.922108e+02    3.52e+01    2.81e+04   1.06e+01   6.91e-01  1.61e+04        1    3.16e-03    1.35e-01\n",
      "  39  2.611816e+02    3.10e+01    2.55e+04   1.00e+01   6.99e-01  1.72e+04        1    3.18e-03    1.39e-01\n",
      "  40  2.341693e+02    2.70e+01    2.30e+04   9.51e+00   7.07e-01  1.85e+04        1    3.11e-03    1.42e-01\n",
      "  41  2.110151e+02    2.32e+01    2.09e+04   8.97e+00   7.15e-01  2.00e+04        1    3.11e-03    1.45e-01\n",
      "  42  1.915231e+02    1.95e+01    1.89e+04   8.42e+00   7.24e-01  2.20e+04        1    3.07e-03    1.48e-01\n",
      "  43  1.754607e+02    1.61e+01    1.69e+04   7.86e+00   7.33e-01  2.45e+04        1    3.78e-03    1.52e-01\n",
      "  44  1.625593e+02    1.29e+01    1.49e+04   7.28e+00   7.44e-01  2.77e+04        1    4.57e-03    1.56e-01\n",
      "  45  1.525168e+02    1.00e+01    1.28e+04   6.69e+00   7.56e-01  3.20e+04        1    3.10e-03    1.60e-01\n",
      "  46  1.450010e+02    7.52e+00    1.08e+04   6.06e+00   7.69e-01  3.79e+04        1    3.10e-03    1.63e-01\n",
      "  47  1.396544e+02    5.35e+00    8.75e+03   5.41e+00   7.85e-01  4.66e+04        1    3.09e-03    1.66e-01\n",
      "  48  1.361015e+02    3.55e+00    6.76e+03   4.71e+00   8.05e-01  6.02e+04        1    3.08e-03    1.69e-01\n",
      "  49  1.339568e+02    2.14e+00    4.87e+03   3.97e+00   8.29e-01  8.43e+04        1    3.20e-03    1.72e-01\n",
      "  50  1.328371e+02    1.12e+00    3.13e+03   3.17e+00   8.61e-01  1.35e+05        1    3.25e-03    1.75e-01\n",
      "  51  1.323772e+02    4.60e-01    1.64e+03   2.29e+00   9.03e-01  2.84e+05        1    3.12e-03    1.78e-01\n",
      "  52  1.322565e+02    1.21e-01    5.69e+02   1.34e+00   9.54e-01  8.51e+05        1    3.12e-03    1.82e-01\n",
      "  53  1.322442e+02    1.23e-02    6.73e+01   4.60e-01   9.94e-01  2.55e+06        1    3.08e-03    1.85e-01\n",
      "  54  1.322440e+02    1.71e-04    1.05e+00   5.74e-02   1.00e+00  7.66e+06        1    3.08e-03    1.88e-01\n",
      "  55  1.322440e+02    1.94e-07    1.97e-02   2.56e-03   1.01e+00  2.30e+07        1    3.11e-03    1.91e-01\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 3764\n",
      "   Parameters : 2830\n",
      "   Iterations : 56\n",
      "         Time : 0.191173 [s]\n",
      " Initial cost : 1.20199 [px]\n",
      "   Final cost : 0.18744 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Filtered observations: 0\n",
      "  => Filtered images: 0\n",
      "\n",
      "==============================================================================\n",
      "Registering image #9 (3)\n",
      "==============================================================================\n",
      "\n",
      "  => Image sees 303 / 1404 points\n",
      "\n",
      "Pose refinement report\n",
      "----------------------\n",
      "    Residuals : 574\n",
      "   Parameters : 6\n",
      "   Iterations : 28\n",
      "         Time : 0.00896311 [s]\n",
      " Initial cost : 0.84301 [px]\n",
      "   Final cost : 0.785824 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Continued observations: 287\n",
      "  => Added observations: 520\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 5378\n",
      "   Parameters : 3553\n",
      "   Iterations : 22\n",
      "         Time : 0.106797 [s]\n",
      " Initial cost : 0.634086 [px]\n",
      "   Final cost : 0.336285 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 0\n",
      "  => Filtered observations: 21\n",
      "  => Changed observations: 0.007810\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 5336\n",
      "   Parameters : 3550\n",
      "   Iterations : 4\n",
      "         Time : 0.0207348 [s]\n",
      " Initial cost : 0.346754 [px]\n",
      "   Final cost : 0.330558 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 6\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.002249\n",
      "\n",
      "==============================================================================\n",
      "Retriangulation\n",
      "==============================================================================\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Retriangulated observations: 0\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  5.842716e+02    0.00e+00    2.73e+02   0.00e+00   0.00e+00  1.00e+04        0    3.82e-03    7.64e-03\n",
      "   1  5.842306e+02    4.10e-02    1.57e+00   5.82e-02   1.00e+00  3.00e+04        1    6.12e-03    1.38e-02\n",
      "   2  5.842306e+02    3.61e-05    2.79e-01   1.54e-02   9.99e-01  9.00e+04        1    4.84e-03    1.87e-02\n",
      "   3  5.842306e+02    2.64e-06    1.25e-02   8.80e-03   1.00e+00  2.70e+05        1    4.90e-03    2.36e-02\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 5348\n",
      "   Parameters : 3559\n",
      "   Iterations : 4\n",
      "         Time : 0.023814 [s]\n",
      " Initial cost : 0.330531 [px]\n",
      "   Final cost : 0.330519 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000000\n",
      "  => Filtered images: 0\n",
      "\n",
      "==============================================================================\n",
      "Registering image #8 (4)\n",
      "==============================================================================\n",
      "\n",
      "  => Image sees 358 / 1229 points\n",
      "\n",
      "Pose refinement report\n",
      "----------------------\n",
      "    Residuals : 698\n",
      "   Parameters : 6\n",
      "   Iterations : 13\n",
      "         Time : 0.00525379 [s]\n",
      " Initial cost : 0.782163 [px]\n",
      "   Final cost : 0.629525 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Continued observations: 345\n",
      "  => Added observations: 411\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 6860\n",
      "   Parameters : 4093\n",
      "   Iterations : 26\n",
      "         Time : 0.195378 [s]\n",
      " Initial cost : 0.464482 [px]\n",
      "   Final cost : 0.431204 [px]\n",
      "  Termination : No convergence\n",
      "\n",
      "  => Merged observations: 5\n",
      "  => Completed observations: 13\n",
      "  => Filtered observations: 50\n",
      "  => Changed observations: 0.019825\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 6786\n",
      "   Parameters : 4078\n",
      "   Iterations : 5\n",
      "         Time : 0.0380139 [s]\n",
      " Initial cost : 0.438552 [px]\n",
      "   Final cost : 0.415879 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 5\n",
      "  => Completed observations: 8\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.003831\n",
      "\n",
      "==============================================================================\n",
      "Retriangulation\n",
      "==============================================================================\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Retriangulated observations: 0\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  1.185048e+03    0.00e+00    1.91e+02   0.00e+00   0.00e+00  1.00e+04        0    3.52e-03    8.96e-03\n",
      "   1  1.184645e+03    4.02e-01    1.67e+00   5.24e-02   1.00e+00  3.00e+04        1    6.70e-03    1.57e-02\n",
      "   2  1.184645e+03    1.90e-04    4.50e-01   3.77e-02   1.01e+00  9.00e+04        1    6.43e-03    2.21e-02\n",
      "   3  1.184645e+03    1.83e-05    9.79e-02   1.41e-02   1.01e+00  2.70e+05        1    6.38e-03    2.85e-02\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 6802\n",
      "   Parameters : 4087\n",
      "   Iterations : 4\n",
      "         Time : 0.0287678 [s]\n",
      " Initial cost : 0.417397 [px]\n",
      "   Final cost : 0.417326 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000000\n",
      "  => Filtered images: 0\n",
      "\n",
      "==============================================================================\n",
      "Registering image #15 (5)\n",
      "==============================================================================\n",
      "\n",
      "  => Image sees 239 / 1531 points\n",
      "\n",
      "Pose refinement report\n",
      "----------------------\n",
      "    Residuals : 466\n",
      "   Parameters : 6\n",
      "   Iterations : 11\n",
      "         Time : 0.00305295 [s]\n",
      " Initial cost : 0.675942 [px]\n",
      "   Final cost : 0.625035 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Continued observations: 232\n",
      "  => Added observations: 288\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 7842\n",
      "   Parameters : 4501\n",
      "   Iterations : 20\n",
      "         Time : 0.178997 [s]\n",
      " Initial cost : 0.425882 [px]\n",
      "   Final cost : 0.380281 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 4\n",
      "  => Filtered observations: 21\n",
      "  => Changed observations: 0.006376\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 7808\n",
      "   Parameters : 4492\n",
      "   Iterations : 4\n",
      "         Time : 0.0377278 [s]\n",
      " Initial cost : 0.433349 [px]\n",
      "   Final cost : 0.422658 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 6\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.001537\n",
      "\n",
      "==============================================================================\n",
      "Retriangulation\n",
      "==============================================================================\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Retriangulated observations: 0\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  1.411627e+03    0.00e+00    3.82e+02   0.00e+00   0.00e+00  1.00e+04        0    4.44e-03    1.04e-02\n",
      "   1  1.411209e+03    4.18e-01    1.80e+00   7.33e-02   1.00e+00  3.00e+04        1    8.28e-03    1.87e-02\n",
      "   2  1.411209e+03    4.92e-04    1.25e+00   7.16e-02   1.01e+00  9.00e+04        1    8.00e-03    2.67e-02\n",
      "   3  1.411209e+03    5.27e-05    2.66e-01   2.83e-02   1.01e+00  2.70e+05        1    7.88e-03    3.46e-02\n",
      "   4  1.411209e+03    1.02e-06    2.12e-02   4.28e-03   1.01e+00  8.10e+05        1    7.97e-03    4.26e-02\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 7820\n",
      "   Parameters : 4501\n",
      "   Iterations : 5\n",
      "         Time : 0.042861 [s]\n",
      " Initial cost : 0.424871 [px]\n",
      "   Final cost : 0.424808 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000000\n",
      "  => Filtered images: 0\n",
      "\n",
      "==============================================================================\n",
      "Registering image #6 (6)\n",
      "==============================================================================\n",
      "\n",
      "  => Image sees 242 / 1594 points\n",
      "\n",
      "Pose refinement report\n",
      "----------------------\n",
      "    Residuals : 476\n",
      "   Parameters : 6\n",
      "   Iterations : 8\n",
      "         Time : 0.00241613 [s]\n",
      " Initial cost : 0.614604 [px]\n",
      "   Final cost : 0.580147 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Continued observations: 238\n",
      "  => Added observations: 466\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 9228\n",
      "   Parameters : 5173\n",
      "   Iterations : 14\n",
      "         Time : 0.152307 [s]\n",
      " Initial cost : 0.399802 [px]\n",
      "   Final cost : 0.379215 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 10\n",
      "  => Filtered observations: 13\n",
      "  => Changed observations: 0.004985\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 9222\n",
      "   Parameters : 5173\n",
      "   Iterations : 3\n",
      "         Time : 0.034405 [s]\n",
      " Initial cost : 0.441479 [px]\n",
      "   Final cost : 0.429498 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000000\n",
      "\n",
      "==============================================================================\n",
      "Retriangulation\n",
      "==============================================================================\n",
      "\n",
      "  => Completed observations: 1\n",
      "  => Merged observations: 0\n",
      "  => Retriangulated observations: 0\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  1.708961e+03    0.00e+00    1.73e+03   0.00e+00   0.00e+00  1.00e+04        0    4.92e-03    1.21e-02\n",
      "   1  1.703616e+03    5.35e+00    7.38e+00   9.66e-02   1.00e+00  3.00e+04        1    1.01e-02    2.22e-02\n",
      "   2  1.703615e+03    5.75e-04    1.35e+00   4.54e-02   1.01e+00  9.00e+04        1    9.19e-03    3.14e-02\n",
      "   3  1.703615e+03    5.14e-05    2.69e-01   1.69e-02   1.01e+00  2.70e+05        1    9.26e-03    4.07e-02\n",
      "   4  1.703615e+03    8.98e-07    1.96e-02   2.42e-03   1.01e+00  8.10e+05        1    9.18e-03    4.99e-02\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 9224\n",
      "   Parameters : 5173\n",
      "   Iterations : 5\n",
      "         Time : 0.050189 [s]\n",
      " Initial cost : 0.430434 [px]\n",
      "   Final cost : 0.42976 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000000\n",
      "  => Filtered images: 0\n",
      "\n",
      "==============================================================================\n",
      "Registering image #10 (7)\n",
      "==============================================================================\n",
      "\n",
      "  => Image sees 220 / 1097 points\n",
      "\n",
      "Pose refinement report\n",
      "----------------------\n",
      "    Residuals : 386\n",
      "   Parameters : 6\n",
      "   Iterations : 12\n",
      "         Time : 0.00268102 [s]\n",
      " Initial cost : 0.724042 [px]\n",
      "   Final cost : 0.577962 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Continued observations: 193\n",
      "  => Added observations: 220\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 8312\n",
      "   Parameters : 3962\n",
      "   Iterations : 19\n",
      "         Time : 0.133281 [s]\n",
      " Initial cost : 0.455934 [px]\n",
      "   Final cost : 0.435373 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 6\n",
      "  => Filtered observations: 24\n",
      "  => Changed observations: 0.006628\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 8276\n",
      "   Parameters : 3944\n",
      "   Iterations : 3\n",
      "         Time : 0.022938 [s]\n",
      " Initial cost : 0.454156 [px]\n",
      "   Final cost : 0.446091 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 4\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000887\n",
      "\n",
      "==============================================================================\n",
      "Retriangulation\n",
      "==============================================================================\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Retriangulated observations: 20\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  7.405830e+04    0.00e+00    2.32e+05   0.00e+00   0.00e+00  1.00e+04        0    5.42e-03    1.34e-02\n",
      "   1  1.417155e+04    5.99e+04    1.06e+05   1.78e+01   9.98e-01  3.00e+04        1    1.35e-02    2.70e-02\n",
      "   2  1.349212e+04    6.79e+02    7.31e+04   1.41e+01   9.67e-01  9.00e+04        1    1.02e-02    3.72e-02\n",
      "   3  1.346041e+04    3.17e+01    9.63e+03   5.21e+00   9.90e-01  2.70e+05        1    1.03e-02    4.75e-02\n",
      "   4  1.345984e+04    5.68e-01    1.76e+02   6.94e-01   1.01e+00  8.10e+05        1    1.04e-02    5.79e-02\n",
      "   5  1.345984e+04    7.44e-04    1.74e+00   4.53e-02   1.04e+00  2.43e+06        1    1.04e-02    6.83e-02\n",
      "   6  1.345984e+04    2.05e-06    1.52e-01   2.17e-03   1.06e+00  7.29e+06        1    1.04e-02    7.87e-02\n",
      "   7  1.345984e+04    7.46e-09    1.03e-02   1.12e-04   1.05e+00  2.19e+07        1    1.07e-02    8.94e-02\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 10062\n",
      "   Parameters : 5467\n",
      "   Iterations : 8\n",
      "         Time : 0.089704 [s]\n",
      " Initial cost : 2.71297 [px]\n",
      "   Final cost : 1.15659 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 6\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 127\n",
      "  => Changed observations: 0.026436\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  4.369977e+03    0.00e+00    2.27e+04   0.00e+00   0.00e+00  1.00e+04        0    5.26e-03    1.32e-02\n",
      "   1  3.266218e+03    1.10e+03    3.25e+04   7.44e+00   9.90e-01  3.00e+04        1    1.06e-02    2.39e-02\n",
      "   2  3.216286e+03    4.99e+01    3.01e+04   8.18e+00   9.32e-01  8.43e+04        1    1.02e-02    3.41e-02\n",
      "   3  3.209350e+03    6.94e+00    4.21e+03   3.16e+00   9.92e-01  2.53e+05        1    1.02e-02    4.43e-02\n",
      "   4  3.209203e+03    1.48e-01    9.97e+01   4.93e-01   1.01e+00  7.58e+05        1    1.00e-02    5.44e-02\n",
      "   5  3.209202e+03    2.90e-04    7.93e-01   3.12e-02   1.02e+00  2.27e+06        1    1.18e-02    6.62e-02\n",
      "   6  3.209202e+03    3.14e-07    2.14e-02   1.05e-03   1.03e+00  6.82e+06        1    1.05e-02    7.69e-02\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 9820\n",
      "   Parameters : 5398\n",
      "   Iterations : 7\n",
      "         Time : 0.077172 [s]\n",
      " Initial cost : 0.667089 [px]\n",
      "   Final cost : 0.571667 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 15\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 15\n",
      "  => Changed observations: 0.006110\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  2.807343e+03    0.00e+00    1.73e+04   0.00e+00   0.00e+00  1.00e+04        0    5.39e-03    1.31e-02\n",
      "   1  1.905232e+03    9.02e+02    8.83e+03   4.86e+00   9.93e-01  3.00e+04        1    1.08e-02    2.39e-02\n",
      "   2  1.878280e+03    2.70e+01    1.46e+04   5.78e+00   9.68e-01  9.00e+04        1    1.03e-02    3.43e-02\n",
      "   3  1.875693e+03    2.59e+00    2.32e+03   2.34e+00   9.95e-01  2.70e+05        1    1.07e-02    4.51e-02\n",
      "   4  1.875638e+03    5.47e-02    4.82e+01   3.45e-01   1.01e+00  8.10e+05        1    1.03e-02    5.54e-02\n",
      "   5  1.875638e+03    1.03e-04    4.30e-01   1.97e-02   1.01e+00  2.43e+06        1    1.03e-02    6.58e-02\n",
      "   6  1.875638e+03    7.67e-08    8.44e-03   5.47e-04   1.02e+00  7.29e+06        1    1.02e-02    7.60e-02\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 9820\n",
      "   Parameters : 5380\n",
      "   Iterations : 7\n",
      "         Time : 0.0763378 [s]\n",
      " Initial cost : 0.534678 [px]\n",
      "   Final cost : 0.437038 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 35\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.007128\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  1.977199e+03    0.00e+00    7.60e+03   0.00e+00   0.00e+00  1.00e+04        0    5.43e-03    1.33e-02\n",
      "   1  1.929647e+03    4.76e+01    1.12e+02   4.67e-01   1.00e+00  3.00e+04        1    1.11e-02    2.44e-02\n",
      "   2  1.929535e+03    1.12e-01    9.34e+01   4.67e-01   1.00e+00  9.00e+04        1    1.05e-02    3.49e-02\n",
      "   3  1.929526e+03    9.35e-03    1.21e+01   1.74e-01   1.01e+00  2.70e+05        1    1.04e-02    4.54e-02\n",
      "   4  1.929526e+03    1.50e-04    5.62e-01   2.39e-02   1.01e+00  8.10e+05        1    1.01e-02    5.55e-02\n",
      "   5  1.929526e+03    4.20e-07    1.78e-02   1.29e-03   1.01e+00  2.43e+06        1    1.01e-02    6.56e-02\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 9890\n",
      "   Parameters : 5380\n",
      "   Iterations : 6\n",
      "         Time : 0.0659361 [s]\n",
      " Initial cost : 0.447123 [px]\n",
      "   Final cost : 0.4417 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 1\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000202\n",
      "  => Filtered images: 0\n",
      "\n",
      "==============================================================================\n",
      "Registering image #14 (8)\n",
      "==============================================================================\n",
      "\n",
      "  => Image sees 205 / 1569 points\n",
      "\n",
      "Pose refinement report\n",
      "----------------------\n",
      "    Residuals : 408\n",
      "   Parameters : 6\n",
      "   Iterations : 13\n",
      "         Time : 0.00313997 [s]\n",
      " Initial cost : 0.675664 [px]\n",
      "   Final cost : 0.637381 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Continued observations: 204\n",
      "  => Added observations: 364\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 5702\n",
      "   Parameters : 2231\n",
      "   Iterations : 12\n",
      "         Time : 0.0627818 [s]\n",
      " Initial cost : 0.491868 [px]\n",
      "   Final cost : 0.455899 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 4\n",
      "  => Completed observations: 11\n",
      "  => Filtered observations: 11\n",
      "  => Changed observations: 0.006623\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 5702\n",
      "   Parameters : 2228\n",
      "   Iterations : 2\n",
      "         Time : 0.0111761 [s]\n",
      " Initial cost : 0.541204 [px]\n",
      "   Final cost : 0.52957 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000000\n",
      "\n",
      "==============================================================================\n",
      "Retriangulation\n",
      "==============================================================================\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Retriangulated observations: 0\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  2.250354e+03    0.00e+00    7.78e+02   0.00e+00   0.00e+00  1.00e+04        0    9.81e-03    2.16e-02\n",
      "   1  2.249164e+03    1.19e+00    8.94e+01   4.53e-01   1.00e+00  3.00e+04        1    2.30e-02    4.47e-02\n",
      "   2  2.249064e+03    1.00e-01    8.50e+01   4.36e-01   1.00e+00  9.00e+04        1    1.98e-02    6.45e-02\n",
      "   3  2.249056e+03    8.17e-03    9.64e+00   1.48e-01   1.01e+00  2.70e+05        1    2.01e-02    8.47e-02\n",
      "   4  2.249056e+03    1.16e-04    4.36e-01   1.89e-02   1.01e+00  8.10e+05        1    1.91e-02    1.04e-01\n",
      "   5  2.249056e+03    2.72e-07    1.15e-02   9.30e-04   1.01e+00  2.43e+06        1    1.83e-02    1.22e-01\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 11028\n",
      "   Parameters : 5908\n",
      "   Iterations : 6\n",
      "         Time : 0.122756 [s]\n",
      " Initial cost : 0.451728 [px]\n",
      "   Final cost : 0.451598 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 7\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.001269\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  2.258222e+03    0.00e+00    5.12e+02   0.00e+00   0.00e+00  1.00e+04        0    8.77e-03    2.15e-02\n",
      "   1  2.257712e+03    5.10e-01    4.10e+00   8.19e-02   1.00e+00  3.00e+04        1    1.93e-02    4.09e-02\n",
      "   2  2.257705e+03    6.38e-03    3.66e+00   8.52e-02   1.00e+00  9.00e+04        1    1.85e-02    5.95e-02\n",
      "   3  2.257705e+03    4.49e-04    9.76e-01   3.13e-02   1.01e+00  2.70e+05        1    1.83e-02    7.78e-02\n",
      "   4  2.257705e+03    6.14e-06    6.67e-02   4.05e-03   1.01e+00  8.10e+05        1    1.80e-02    9.59e-02\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 11028\n",
      "   Parameters : 5905\n",
      "   Iterations : 5\n",
      "         Time : 0.096344 [s]\n",
      " Initial cost : 0.452517 [px]\n",
      "   Final cost : 0.452465 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000000\n",
      "  => Filtered images: 0\n",
      "\n",
      "==============================================================================\n",
      "Registering image #3 (9)\n",
      "==============================================================================\n",
      "\n",
      "  => Image sees 183 / 1203 points\n",
      "\n",
      "Pose refinement report\n",
      "----------------------\n",
      "    Residuals : 362\n",
      "   Parameters : 6\n",
      "   Iterations : 16\n",
      "         Time : 0.00619602 [s]\n",
      " Initial cost : 0.659512 [px]\n",
      "   Final cost : 0.634579 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Continued observations: 181\n",
      "  => Added observations: 217\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 8326\n",
      "   Parameters : 4133\n",
      "   Iterations : 12\n",
      "         Time : 0.155026 [s]\n",
      " Initial cost : 0.439919 [px]\n",
      "   Final cost : 0.411742 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 0\n",
      "  => Filtered observations: 10\n",
      "  => Changed observations: 0.002183\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 8306\n",
      "   Parameters : 4130\n",
      "   Iterations : 3\n",
      "         Time : 0.0390711 [s]\n",
      " Initial cost : 0.486037 [px]\n",
      "   Final cost : 0.477442 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000000\n",
      "\n",
      "==============================================================================\n",
      "Retriangulation\n",
      "==============================================================================\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Retriangulated observations: 0\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  2.463012e+03    0.00e+00    1.04e+03   0.00e+00   0.00e+00  1.00e+04        0    1.04e-02    2.45e-02\n",
      "   1  2.461944e+03    1.07e+00    4.43e+02   7.74e-01   1.01e+00  3.00e+04        1    3.01e-02    5.47e-02\n",
      "   2  2.461763e+03    1.81e-01    1.64e+02   5.44e-01   1.00e+00  9.00e+04        1    2.18e-02    7.65e-02\n",
      "   3  2.461749e+03    1.34e-02    1.52e+01   1.69e-01   1.01e+00  2.70e+05        1    2.03e-02    9.69e-02\n",
      "   4  2.461749e+03    1.65e-04    5.05e-01   2.00e-02   1.01e+00  8.10e+05        1    1.98e-02    1.17e-01\n",
      "   5  2.461749e+03    3.30e-07    1.37e-02   9.09e-04   1.01e+00  2.43e+06        1    2.01e-02    1.37e-01\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 11804\n",
      "   Parameters : 6229\n",
      "   Iterations : 6\n",
      "         Time : 0.137436 [s]\n",
      " Initial cost : 0.456792 [px]\n",
      "   Final cost : 0.456675 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000000\n",
      "  => Filtered images: 0\n",
      "\n",
      "==============================================================================\n",
      "Registering image #2 (10)\n",
      "==============================================================================\n",
      "\n",
      "  => Image sees 253 / 819 points\n",
      "\n",
      "Pose refinement report\n",
      "----------------------\n",
      "    Residuals : 492\n",
      "   Parameters : 6\n",
      "   Iterations : 14\n",
      "         Time : 0.00479293 [s]\n",
      " Initial cost : 0.666177 [px]\n",
      "   Final cost : 0.635228 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Continued observations: 245\n",
      "  => Added observations: 278\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 8298\n",
      "   Parameters : 3995\n",
      "   Iterations : 20\n",
      "         Time : 0.248322 [s]\n",
      " Initial cost : 0.467084 [px]\n",
      "   Final cost : 0.432724 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 6\n",
      "  => Completed observations: 6\n",
      "  => Filtered observations: 21\n",
      "  => Changed observations: 0.007337\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 8272\n",
      "   Parameters : 3992\n",
      "   Iterations : 2\n",
      "         Time : 0.026401 [s]\n",
      " Initial cost : 0.499044 [px]\n",
      "   Final cost : 0.488344 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 2\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000446\n",
      "\n",
      "==============================================================================\n",
      "Retriangulation\n",
      "==============================================================================\n",
      "\n",
      "  => Completed observations: 1\n",
      "  => Merged observations: 0\n",
      "  => Retriangulated observations: 0\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  2.833037e+03    0.00e+00    3.61e+03   0.00e+00   0.00e+00  1.00e+04        0    1.14e-02    2.62e-02\n",
      "   1  2.829653e+03    3.38e+00    4.67e+02   4.96e-01   1.00e+00  3.00e+04        1    2.42e-02    5.04e-02\n",
      "   2  2.829499e+03    1.54e-01    1.24e+02   4.14e-01   1.00e+00  9.00e+04        1    2.30e-02    7.35e-02\n",
      "   3  2.829490e+03    9.00e-03    1.00e+01   1.17e-01   1.00e+00  2.70e+05        1    2.29e-02    9.64e-02\n",
      "   4  2.829490e+03    8.31e-05    2.18e-01   1.20e-02   1.00e+00  8.10e+05        1    2.32e-02    1.20e-01\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 12826\n",
      "   Parameters : 6589\n",
      "   Iterations : 5\n",
      "         Time : 0.12031 [s]\n",
      " Initial cost : 0.469981 [px]\n",
      "   Final cost : 0.469687 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000000\n",
      "  => Filtered images: 0\n",
      "\n",
      "==============================================================================\n",
      "Registering image #11 (11)\n",
      "==============================================================================\n",
      "\n",
      "  => Image sees 167 / 1129 points\n",
      "\n",
      "Pose refinement report\n",
      "----------------------\n",
      "    Residuals : 314\n",
      "   Parameters : 6\n",
      "   Iterations : 7\n",
      "         Time : 0.00230217 [s]\n",
      " Initial cost : 0.669811 [px]\n",
      "   Final cost : 0.659079 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Continued observations: 157\n",
      "  => Added observations: 326\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 5192\n",
      "   Parameters : 2240\n",
      "   Iterations : 15\n",
      "         Time : 0.123552 [s]\n",
      " Initial cost : 0.500508 [px]\n",
      "   Final cost : 0.466195 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 3\n",
      "  => Filtered observations: 22\n",
      "  => Changed observations: 0.007921\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 5154\n",
      "   Parameters : 2234\n",
      "   Iterations : 3\n",
      "         Time : 0.0238609 [s]\n",
      " Initial cost : 0.538433 [px]\n",
      "   Final cost : 0.526313 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000000\n",
      "\n",
      "==============================================================================\n",
      "Retriangulation\n",
      "==============================================================================\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Retriangulated observations: 2\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  3.173992e+03    0.00e+00    4.58e+03   0.00e+00   0.00e+00  1.00e+04        0    1.22e-02    2.88e-02\n",
      "   1  3.168749e+03    5.24e+00    3.97e+01   4.52e-01   1.00e+00  3.00e+04        1    2.67e-02    5.59e-02\n",
      "   2  3.168687e+03    6.22e-02    3.10e+01   2.05e-01   1.00e+00  9.00e+04        1    2.47e-02    8.08e-02\n",
      "   3  3.168683e+03    3.18e-03    2.65e+00   5.59e-02   1.00e+00  2.70e+05        1    2.46e-02    1.06e-01\n",
      "   4  3.168683e+03    2.65e-05    8.27e-02   5.46e-03   1.00e+00  8.10e+05        1    2.47e-02    1.31e-01\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 13758\n",
      "   Parameters : 7078\n",
      "   Iterations : 5\n",
      "         Time : 0.131728 [s]\n",
      " Initial cost : 0.480314 [px]\n",
      "   Final cost : 0.479912 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 2\n",
      "  => Changed observations: 0.000291\n",
      "  => Filtered images: 0\n",
      "\n",
      "==============================================================================\n",
      "Registering image #5 (12)\n",
      "==============================================================================\n",
      "\n",
      "  => Image sees 160 / 1239 points\n",
      "\n",
      "Pose refinement report\n",
      "----------------------\n",
      "    Residuals : 304\n",
      "   Parameters : 6\n",
      "   Iterations : 15\n",
      "         Time : 0.00455523 [s]\n",
      " Initial cost : 0.737425 [px]\n",
      "   Final cost : 0.690268 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Continued observations: 152\n",
      "  => Added observations: 467\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 5326\n",
      "   Parameters : 2507\n",
      "   Iterations : 26\n",
      "         Time : 0.128381 [s]\n",
      " Initial cost : 0.551418 [px]\n",
      "   Final cost : 0.49116 [px]\n",
      "  Termination : No convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 4\n",
      "  => Filtered observations: 29\n",
      "  => Changed observations: 0.010806\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 5276\n",
      "   Parameters : 2492\n",
      "   Iterations : 2\n",
      "         Time : 0.010637 [s]\n",
      " Initial cost : 0.527115 [px]\n",
      "   Final cost : 0.512327 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 2\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000660\n",
      "\n",
      "==============================================================================\n",
      "Registering image #13 (13)\n",
      "==============================================================================\n",
      "\n",
      "  => Image sees 263 / 1176 points\n",
      "\n",
      "Pose refinement report\n",
      "----------------------\n",
      "    Residuals : 512\n",
      "   Parameters : 6\n",
      "   Iterations : 12\n",
      "         Time : 0.0037601 [s]\n",
      " Initial cost : 0.743436 [px]\n",
      "   Final cost : 0.631962 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Continued observations: 255\n",
      "  => Added observations: 367\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 5156\n",
      "   Parameters : 2285\n",
      "   Iterations : 19\n",
      "         Time : 0.0904832 [s]\n",
      " Initial cost : 0.558387 [px]\n",
      "   Final cost : 0.533291 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 9\n",
      "  => Completed observations: 13\n",
      "  => Filtered observations: 35\n",
      "  => Changed observations: 0.018725\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 5112\n",
      "   Parameters : 2264\n",
      "   Iterations : 3\n",
      "         Time : 0.015269 [s]\n",
      " Initial cost : 0.569307 [px]\n",
      "   Final cost : 0.552379 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 13\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.004302\n",
      "\n",
      "==============================================================================\n",
      "Retriangulation\n",
      "==============================================================================\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Retriangulated observations: 3\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  1.159834e+04    0.00e+00    1.76e+04   0.00e+00   0.00e+00  1.00e+04        0    9.37e-03    2.38e-02\n",
      "   1  6.844693e+03    4.75e+03    1.68e+04   5.54e+00   9.68e-01  3.00e+04        1    1.97e-02    4.36e-02\n",
      "   2  6.756191e+03    8.85e+01    3.73e+03   2.25e+00   9.84e-01  9.00e+04        1    1.80e-02    6.17e-02\n",
      "   3  6.755764e+03    4.27e-01    2.49e+02   5.56e-01   1.00e+00  2.70e+05        1    1.79e-02    7.96e-02\n",
      "   4  6.755761e+03    3.12e-03    2.13e+00   5.54e-02   1.00e+00  8.10e+05        1    1.83e-02    9.80e-02\n",
      "   5  6.755761e+03    3.90e-06    4.37e-02   1.96e-03   1.01e+00  2.43e+06        1    1.81e-02    1.16e-01\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 16178\n",
      "   Parameters : 8188\n",
      "   Iterations : 6\n",
      "         Time : 0.116579 [s]\n",
      " Initial cost : 0.846712 [px]\n",
      "   Final cost : 0.646212 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 1\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 11\n",
      "  => Changed observations: 0.001483\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  3.958856e+03    0.00e+00    4.64e+03   0.00e+00   0.00e+00  1.00e+04        0    9.60e-03    2.37e-02\n",
      "   1  3.774244e+03    1.85e+02    3.80e+03   2.24e+00   9.99e-01  3.00e+04        1    2.15e-02    4.52e-02\n",
      "   2  3.772807e+03    1.44e+00    7.44e+02   9.66e-01   1.00e+00  9.00e+04        1    1.84e-02    6.36e-02\n",
      "   3  3.772736e+03    7.01e-02    5.64e+01   2.59e-01   1.00e+00  2.70e+05        1    1.79e-02    8.16e-02\n",
      "   4  3.772736e+03    6.70e-04    7.70e-01   2.66e-02   1.00e+00  8.10e+05        1    1.83e-02    9.99e-02\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 16158\n",
      "   Parameters : 8179\n",
      "   Iterations : 5\n",
      "         Time : 0.100419 [s]\n",
      " Initial cost : 0.494984 [px]\n",
      "   Final cost : 0.483208 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 1\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000124\n",
      "  => Filtered images: 0\n",
      "\n",
      "==============================================================================\n",
      "Registering image #12 (14)\n",
      "==============================================================================\n",
      "\n",
      "  => Image sees 318 / 996 points\n",
      "\n",
      "Pose refinement report\n",
      "----------------------\n",
      "    Residuals : 618\n",
      "   Parameters : 6\n",
      "   Iterations : 14\n",
      "         Time : 0.00491881 [s]\n",
      " Initial cost : 0.699507 [px]\n",
      "   Final cost : 0.681713 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Continued observations: 305\n",
      "  => Added observations: 139\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 5182\n",
      "   Parameters : 1877\n",
      "   Iterations : 19\n",
      "         Time : 0.0874209 [s]\n",
      " Initial cost : 0.621802 [px]\n",
      "   Final cost : 0.553514 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 10\n",
      "  => Completed observations: 10\n",
      "  => Filtered observations: 42\n",
      "  => Changed observations: 0.021074\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 5118\n",
      "   Parameters : 1853\n",
      "   Iterations : 2\n",
      "         Time : 0.0100012 [s]\n",
      " Initial cost : 0.593735 [px]\n",
      "   Final cost : 0.572888 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 6\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.002062\n",
      "\n",
      "==============================================================================\n",
      "Registering image #4 (15)\n",
      "==============================================================================\n",
      "\n",
      "  => Image sees 173 / 733 points\n",
      "\n",
      "Pose refinement report\n",
      "----------------------\n",
      "    Residuals : 324\n",
      "   Parameters : 6\n",
      "   Iterations : 9\n",
      "         Time : 0.00172091 [s]\n",
      " Initial cost : 0.634299 [px]\n",
      "   Final cost : 0.588077 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Continued observations: 161\n",
      "  => Added observations: 64\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 6384\n",
      "   Parameters : 2384\n",
      "   Iterations : 15\n",
      "         Time : 0.074229 [s]\n",
      " Initial cost : 0.504007 [px]\n",
      "   Final cost : 0.489824 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 5\n",
      "  => Completed observations: 5\n",
      "  => Filtered observations: 24\n",
      "  => Changed observations: 0.008685\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 6346\n",
      "   Parameters : 2366\n",
      "   Iterations : 2\n",
      "         Time : 0.010777 [s]\n",
      " Initial cost : 0.542497 [px]\n",
      "   Final cost : 0.535621 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Merged observations: 0\n",
      "  => Completed observations: 4\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.001027\n",
      "\n",
      "==============================================================================\n",
      "Retriangulation\n",
      "==============================================================================\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Retriangulated observations: 7\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  1.407102e+04    0.00e+00    3.41e+04   0.00e+00   0.00e+00  1.00e+04        0    1.02e-02    2.56e-02\n",
      "   1  6.899378e+03    7.17e+03    2.49e+03   1.12e+00   9.79e-01  3.00e+04        1    2.14e-02    4.70e-02\n",
      "   2  6.879272e+03    2.01e+01    4.27e+01   5.32e-01   9.77e-01  9.00e+04        1    1.97e-02    6.67e-02\n",
      "   3  6.879258e+03    1.39e-02    2.49e+00   4.64e-02   9.80e-01  2.70e+05        1    1.97e-02    8.64e-02\n",
      "   4  6.879258e+03    2.07e-05    1.72e-01   3.74e-03   9.94e-01  8.10e+05        1    1.98e-02    1.06e-01\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 17430\n",
      "   Parameters : 8392\n",
      "   Iterations : 5\n",
      "         Time : 0.106864 [s]\n",
      " Initial cost : 0.898492 [px]\n",
      "   Final cost : 0.628235 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 8\n",
      "  => Changed observations: 0.000918\n",
      "\n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "\n",
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  4.517381e+03    0.00e+00    5.86e+03   0.00e+00   0.00e+00  1.00e+04        0    1.00e-02    2.52e-02\n",
      "   1  4.478544e+03    3.88e+01    1.13e+02   4.17e-01   9.99e-01  3.00e+04        1    2.16e-02    4.69e-02\n",
      "   2  4.478479e+03    6.46e-02    1.20e+01   1.10e-01   1.00e+00  9.00e+04        1    2.11e-02    6.80e-02\n",
      "   3  4.478479e+03    4.07e-04    5.21e-01   1.80e-02   1.00e+00  2.70e+05        1    1.98e-02    8.78e-02\n",
      "\n",
      "\n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "    Residuals : 17414\n",
      "   Parameters : 8386\n",
      "   Iterations : 4\n",
      "         Time : 0.088438 [s]\n",
      " Initial cost : 0.509324 [px]\n",
      "   Final cost : 0.507126 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "  => Completed observations: 0\n",
      "  => Merged observations: 0\n",
      "  => Filtered observations: 0\n",
      "  => Changed observations: 0.000000\n",
      "  => Filtered images: 0\n",
      "\n",
      "Elapsed time: 0.072 [minutes]\n",
      "\n",
      "                Dataset: haiper - Scene: bike\n",
      "                Reconstruction count: 1\n",
      "                Best reconstruction registered image count: 15\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "reconstruction_root_directory = Path('./inference')\n",
    "reconstruction_root_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "datasets = [\n",
    "    directory for directory in os.listdir(train_or_test_directory)\n",
    "    if (train_or_test_directory / directory).is_dir() and (directory in df['dataset'].unique())\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "        \n",
    "    dataset_directory = train_or_test_directory / dataset\n",
    "    scenes = [\n",
    "        directory for directory in os.listdir(dataset_directory)\n",
    "        if (dataset_directory / directory).is_dir() and (directory in df['scene'].unique())\n",
    "    ]\n",
    "    \n",
    "    for scene in scenes:\n",
    "        \n",
    "        scene_directory = dataset_directory / scene\n",
    "        image_paths = sorted(glob(str(scene_directory / 'images' / '*')))\n",
    "        scene_image_count = len(image_paths)\n",
    "        \n",
    "        scene_reconstruction_directory = reconstruction_root_directory / dataset / scene\n",
    "        scene_reconstruction_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for file_or_directory in os.listdir(scene_reconstruction_directory):\n",
    "            file_or_directory_path = scene_reconstruction_directory / file_or_directory\n",
    "            if file_or_directory_path.is_file():\n",
    "                os.remove(file_or_directory_path)\n",
    "            elif file_or_directory_path.is_dir():\n",
    "                shutil.rmtree(file_or_directory_path)\n",
    "\n",
    "        # Create COLMAP database and its tables for the current reconstruction\n",
    "        database_path = scene_reconstruction_directory / 'database.db'\n",
    "        database_uri = f'file:{database_path}?mode=rwc'\n",
    "        colmap_database = COLMAPDatabase.connect(database_uri, uri=True)\n",
    "        colmap_database.create_tables()\n",
    "        \n",
    "        # Select images if scene image count is above the specified threshold\n",
    "        if scene_image_count > config['image_selection']['image_count']:\n",
    "            if config['image_selection']['criteria'] == 'similarity':\n",
    "                # Load image selection model with specified configurations\n",
    "                image_selection_device = torch.device(config['image_selection']['device'])\n",
    "                image_selection_model = load_feature_extractor(**config['image_selection']['model'])\n",
    "                image_selection_model = image_selection_model.eval().to(image_selection_device)\n",
    "                image_selection_transforms = create_image_selection_transforms(**config['image_selection']['transforms'])\n",
    "\n",
    "                image_selection_data_loader = prepare_dataloader(\n",
    "                    image_paths=image_paths,\n",
    "                    transforms=image_selection_transforms,\n",
    "                    batch_size=config['image_selection']['batch_size'],\n",
    "                    num_workers=config['image_selection']['num_workers']\n",
    "                )\n",
    "                image_selection_features = []\n",
    "\n",
    "                for idx, inputs in enumerate(tqdm(image_selection_data_loader)):\n",
    "                    inputs = inputs.to(image_selection_device)\n",
    "                    batch_image_selection_features = extract_features(\n",
    "                        inputs=inputs,\n",
    "                        model=image_selection_model,\n",
    "                        pooling_type=config['image_selection']['pooling_type'],\n",
    "                        device=image_selection_device,\n",
    "                        amp=config['image_selection']['amp']\n",
    "                    )\n",
    "                    image_selection_features.append(batch_image_selection_features)\n",
    "\n",
    "                image_selection_features = torch.cat(image_selection_features, dim=0).numpy()\n",
    "                # Select images with the highest mean cosine similarity because they are more likely to be registered\n",
    "                image_paths = select_images(\n",
    "                    image_paths=image_paths,\n",
    "                    image_selection_features=image_selection_features,\n",
    "                    image_count=config['image_selection']['image_count']\n",
    "                )\n",
    "                del image_selection_device, image_selection_model, image_selection_transforms, image_selection_data_loader, image_selection_features\n",
    "            elif config['image_selection']['criteria'] == 'step_size':\n",
    "                # Select images with step size\n",
    "                step_size = int(np.ceil(len(image_paths) / config['image_selection']['image_count']))\n",
    "                image_paths = image_paths[::step_size]\n",
    "            else:\n",
    "                raise ValueError(f'Invalid image selection criteria {config[\"image_selection\"][\"criteria\"]}')\n",
    "                \n",
    "        scene_max_image_size = df.loc[df['scene'] == scene, ['image_height', 'image_width']].max().max()\n",
    "\n",
    "        # Create brute force image pairs from image paths\n",
    "        image_pair_indices = create_image_pairs(image_paths=image_paths)\n",
    "        first_image_keypoints = []\n",
    "        second_image_keypoints = []\n",
    "\n",
    "        for image_pair_idx, (first_image_idx, second_image_idx) in enumerate(tqdm(image_pair_indices)):\n",
    "\n",
    "            image1 = cv2.imread(str(image_paths[image_pair_indices[image_pair_idx][0]]))\n",
    "            image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            image2 = cv2.imread(str(image_paths[image_pair_indices[image_pair_idx][1]]))\n",
    "            image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if scene_max_image_size > 3000:\n",
    "\n",
    "                superglue_outputs = superglue_match_images(\n",
    "                    image1=image1,\n",
    "                    image2=image2,\n",
    "                    model=superglue_model,\n",
    "                    device=image_matching_device,\n",
    "                    amp=False,\n",
    "                    transforms={\n",
    "                        'resize': True,\n",
    "                        'resize_shape': 1920,\n",
    "                        'resize_longest_edge': True,\n",
    "                        'scale': True,\n",
    "                        'grayscale': True,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            else:\n",
    "\n",
    "                superglue_outputs = superglue_match_images(\n",
    "                    image1=image1,\n",
    "                    image2=image2,\n",
    "                    model=superglue_model,\n",
    "                    device=image_matching_device,\n",
    "                    amp=False,\n",
    "                    transforms=superglue_transforms\n",
    "                )\n",
    "\n",
    "            first_image_keypoints.append(superglue_outputs['keypoints0'])\n",
    "            second_image_keypoints.append(superglue_outputs['keypoints1'])\n",
    "\n",
    "        write_matches(\n",
    "            image_paths=image_paths,\n",
    "            image_pair_indices=image_pair_indices,\n",
    "            first_image_keypoints=first_image_keypoints,\n",
    "            second_image_keypoints=second_image_keypoints,\n",
    "            output_directory=scene_reconstruction_directory\n",
    "        )\n",
    "\n",
    "        push_to_database(\n",
    "            colmap_database=colmap_database,\n",
    "            dataset_directory=scene_reconstruction_directory,\n",
    "            image_directory=scene_directory / 'images',\n",
    "            camera_model='simple-radial',\n",
    "            single_camera=True\n",
    "        )\n",
    "        \n",
    "        sift_matching_options = pycolmap.SiftMatchingOptions(**config['sift_matching'])\n",
    "        exhaustive_matching_options = pycolmap.ExhaustiveMatchingOptions(**config['exhaustive_matching'])\n",
    "\n",
    "        pycolmap.match_exhaustive(\n",
    "            database_path=database_path,\n",
    "            sift_options=sift_matching_options,\n",
    "            matching_options=exhaustive_matching_options,\n",
    "            device=pycolmap.Device(config['colmap']['device']),\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        incremental_mapper_options = pycolmap.IncrementalMapperOptions(**config['incremental_mapper'])\n",
    "\n",
    "        reconstructions = pycolmap.incremental_mapping(\n",
    "            database_path=database_path,\n",
    "            image_path=scene_directory / 'images',\n",
    "            output_path=scene_reconstruction_directory,\n",
    "            options=incremental_mapper_options\n",
    "        )\n",
    "        \n",
    "        if len(reconstructions) > 0:\n",
    "\n",
    "            best_registered_image_count = 0\n",
    "            best_reconstruction_idx = None\n",
    "\n",
    "            for reconstruction_idx in reconstructions.keys():\n",
    "                if reconstructions[reconstruction_idx].num_reg_images() > best_registered_image_count:\n",
    "                    best_reconstruction_idx = reconstruction_idx\n",
    "                    best_registered_image_count = reconstructions[reconstruction_idx].num_reg_images()\n",
    "\n",
    "            best_reconstruction = reconstructions[best_reconstruction_idx]\n",
    "        else:\n",
    "            best_registered_image_count = 0\n",
    "            best_reconstruction_idx = None\n",
    "            best_reconstruction = None\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f'''\n",
    "                Dataset: {dataset} - Scene: {scene}\n",
    "                Reconstruction count: {len(reconstructions)}\n",
    "                Best reconstruction registered image count: {best_registered_image_count}\n",
    "                '''\n",
    "            )\n",
    "\n",
    "        if best_reconstruction is not None:\n",
    "            registered_images = {image.name: image for image in best_reconstruction.images.values()}\n",
    "        else:\n",
    "            registered_images = {}\n",
    "            \n",
    "        for idx, row in df.loc[(df['dataset'] == dataset) & (df['scene'] == scene)].iterrows():\n",
    "            if row['image_id'] in registered_images:\n",
    "                rotation_matrix_prediction = registered_images[row['image_id']].rotmat()\n",
    "                translation_vector_prediction = registered_images[row['image_id']].tvec\n",
    "                df.loc[idx, 'rotation_matrix'] = ';'.join([str(x) for x in rotation_matrix_prediction.reshape(-1)])\n",
    "                df.loc[idx, 'translation_vector'] = ';'.join([str(x) for x in translation_vector_prediction.reshape(-1)])\n",
    "            else:\n",
    "                df.loc[idx, 'rotation_matrix'] = np.nan\n",
    "                df.loc[idx, 'translation_vector'] = np.nan\n",
    "\n",
    "        # Fill unregistered images rotation matrices with the prediction mean or zeros\n",
    "        scene_rotation_matrix_predictions = df.loc[df['scene'] == scene, 'rotation_matrix'].dropna().apply(lambda x: np.array(str(x).split(';'), dtype=np.float64).reshape(1, 3, 3)).values\n",
    "        if scene_rotation_matrix_predictions.shape[0] == 0:\n",
    "            rotation_matrix_fill_value = np.zeros((3, 3))\n",
    "        else:\n",
    "            rotation_matrix_fill_value = np.mean(np.concatenate(scene_rotation_matrix_predictions, axis=0), axis=0)\n",
    "        df.loc[(df['scene'] == scene) & (df['rotation_matrix'].isnull()), 'rotation_matrix'] = ';'.join([str(x) for x in rotation_matrix_fill_value.reshape(-1)])\n",
    "\n",
    "        # Fill unregistered images translation vectors with the prediction mean or zeros\n",
    "        scene_translation_vector_predictions = df.loc[df['scene'] == scene, 'translation_vector'].dropna().apply(lambda x: np.array(str(x).split(';'), dtype=np.float64).reshape(1, 3)).values\n",
    "        if scene_translation_vector_predictions.shape[0] == 0:\n",
    "            translation_vector_fill_value = np.zeros((3, 1))\n",
    "        else:\n",
    "            translation_vector_fill_value = np.mean(np.concatenate(scene_translation_vector_predictions, axis=0), axis=0)\n",
    "        df.loc[(df['scene'] == scene) & (df['translation_vector'].isnull()), 'translation_vector'] = ';'.join([str(x) for x in translation_vector_fill_value.reshape(-1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91afce2",
   "metadata": {
    "papermill": {
     "duration": 0.020367,
     "end_time": "2023-05-28T15:47:47.095891",
     "exception": false,
     "start_time": "2023-05-28T15:47:47.075524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df9708df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:47:47.138840Z",
     "iopub.status.busy": "2023-05-28T15:47:47.138490Z",
     "iopub.status.idle": "2023-05-28T15:47:47.147298Z",
     "shell.execute_reply": "2023-05-28T15:47:47.146432Z"
    },
    "papermill": {
     "duration": 0.032528,
     "end_time": "2023-05-28T15:47:47.149264",
     "exception": false,
     "start_time": "2023-05-28T15:47:47.116736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_submission = df.loc[:, ['image_path', 'dataset', 'scene', 'rotation_matrix', 'translation_vector']]\n",
    "df_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c704e006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T15:47:47.193047Z",
     "iopub.status.busy": "2023-05-28T15:47:47.191509Z",
     "iopub.status.idle": "2023-05-28T15:47:47.204498Z",
     "shell.execute_reply": "2023-05-28T15:47:47.203567Z"
    },
    "papermill": {
     "duration": 0.036236,
     "end_time": "2023-05-28T15:47:47.206324",
     "exception": false,
     "start_time": "2023-05-28T15:47:47.170088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>dataset</th>\n",
       "      <th>scene</th>\n",
       "      <th>rotation_matrix</th>\n",
       "      <th>translation_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>haiper/bike/images/image_004.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>0.812080225964599;-0.1825040479125909;0.554272...</td>\n",
       "      <td>-1.1095910515919052;-1.9969069555757961;3.4243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>haiper/bike/images/image_029.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>0.369592223922397;-0.2867559565002921;0.883839...</td>\n",
       "      <td>-1.4564524899631375;-2.6847671925134544;5.3244...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>haiper/bike/images/image_038.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>0.14455187093106092;-0.3645288182522968;0.9199...</td>\n",
       "      <td>-1.3074796374742483;-1.9726652982643855;3.4985...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>haiper/bike/images/image_049.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>-0.4603243832999029;-0.23564902521201422;0.855...</td>\n",
       "      <td>0.09043729771431355;-2.691694512489184;4.25853...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haiper/bike/images/image_062.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>-0.881387717212236;0.2507332221145657;-0.40036...</td>\n",
       "      <td>1.4413653948995497;-1.9054030681489025;3.86473...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>haiper/bike/images/image_076.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>0.575339778946482;0.3302348075213795;-0.748284...</td>\n",
       "      <td>1.0145536103240511;-1.1454807789193793;2.02291...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>haiper/bike/images/image_088.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>0.9998804098557524;-4.959447925265357e-05;0.01...</td>\n",
       "      <td>-1.3749439190528743;-1.7921468419983213;2.6520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>haiper/bike/images/image_094.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>0.9891850321058375;-0.08647223607253951;0.1184...</td>\n",
       "      <td>-1.3209920598657354;-2.923572528560199;4.36381...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>haiper/bike/images/image_101.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>0.9492955556094487;0.1501502199166534;-0.27621...</td>\n",
       "      <td>-0.8702004894405444;-0.3342177873043161;1.7002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>haiper/bike/images/image_115.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>0.34102840661975153;0.18152531869784239;-0.922...</td>\n",
       "      <td>0.9069415594501745;-2.3842047219071243;2.87325...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>haiper/bike/images/image_119.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>-0.41825615731095134;0.3470453523865557;-0.839...</td>\n",
       "      <td>0.573382625578278;-2.6116658858806496;3.778044...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>haiper/bike/images/image_128.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>-0.9502137395654826;0.07313544803066031;0.3028...</td>\n",
       "      <td>-0.431035563823642;-3.133904864671361;5.480650...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>haiper/bike/images/image_137.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>-0.5089816654185302;0.2548893975742002;-0.8221...</td>\n",
       "      <td>1.5909275749162968;0.015245888235008375;3.1708...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>haiper/bike/images/image_139.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>-0.04290372260486208;0.35282780746281706;-0.93...</td>\n",
       "      <td>1.5652473187723421;-1.1092173102934066;2.59331...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>haiper/bike/images/image_150.jpeg</td>\n",
       "      <td>haiper</td>\n",
       "      <td>bike</td>\n",
       "      <td>0.7162024370917027;0.3185737239274492;-0.62093...</td>\n",
       "      <td>0.06275027285231641;-1.7262900077114107;2.2653...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_path dataset scene  \\\n",
       "0   haiper/bike/images/image_004.jpeg  haiper  bike   \n",
       "1   haiper/bike/images/image_029.jpeg  haiper  bike   \n",
       "2   haiper/bike/images/image_038.jpeg  haiper  bike   \n",
       "3   haiper/bike/images/image_049.jpeg  haiper  bike   \n",
       "4   haiper/bike/images/image_062.jpeg  haiper  bike   \n",
       "5   haiper/bike/images/image_076.jpeg  haiper  bike   \n",
       "6   haiper/bike/images/image_088.jpeg  haiper  bike   \n",
       "7   haiper/bike/images/image_094.jpeg  haiper  bike   \n",
       "8   haiper/bike/images/image_101.jpeg  haiper  bike   \n",
       "9   haiper/bike/images/image_115.jpeg  haiper  bike   \n",
       "10  haiper/bike/images/image_119.jpeg  haiper  bike   \n",
       "11  haiper/bike/images/image_128.jpeg  haiper  bike   \n",
       "12  haiper/bike/images/image_137.jpeg  haiper  bike   \n",
       "13  haiper/bike/images/image_139.jpeg  haiper  bike   \n",
       "14  haiper/bike/images/image_150.jpeg  haiper  bike   \n",
       "\n",
       "                                      rotation_matrix  \\\n",
       "0   0.812080225964599;-0.1825040479125909;0.554272...   \n",
       "1   0.369592223922397;-0.2867559565002921;0.883839...   \n",
       "2   0.14455187093106092;-0.3645288182522968;0.9199...   \n",
       "3   -0.4603243832999029;-0.23564902521201422;0.855...   \n",
       "4   -0.881387717212236;0.2507332221145657;-0.40036...   \n",
       "5   0.575339778946482;0.3302348075213795;-0.748284...   \n",
       "6   0.9998804098557524;-4.959447925265357e-05;0.01...   \n",
       "7   0.9891850321058375;-0.08647223607253951;0.1184...   \n",
       "8   0.9492955556094487;0.1501502199166534;-0.27621...   \n",
       "9   0.34102840661975153;0.18152531869784239;-0.922...   \n",
       "10  -0.41825615731095134;0.3470453523865557;-0.839...   \n",
       "11  -0.9502137395654826;0.07313544803066031;0.3028...   \n",
       "12  -0.5089816654185302;0.2548893975742002;-0.8221...   \n",
       "13  -0.04290372260486208;0.35282780746281706;-0.93...   \n",
       "14  0.7162024370917027;0.3185737239274492;-0.62093...   \n",
       "\n",
       "                                   translation_vector  \n",
       "0   -1.1095910515919052;-1.9969069555757961;3.4243...  \n",
       "1   -1.4564524899631375;-2.6847671925134544;5.3244...  \n",
       "2   -1.3074796374742483;-1.9726652982643855;3.4985...  \n",
       "3   0.09043729771431355;-2.691694512489184;4.25853...  \n",
       "4   1.4413653948995497;-1.9054030681489025;3.86473...  \n",
       "5   1.0145536103240511;-1.1454807789193793;2.02291...  \n",
       "6   -1.3749439190528743;-1.7921468419983213;2.6520...  \n",
       "7   -1.3209920598657354;-2.923572528560199;4.36381...  \n",
       "8   -0.8702004894405444;-0.3342177873043161;1.7002...  \n",
       "9   0.9069415594501745;-2.3842047219071243;2.87325...  \n",
       "10  0.573382625578278;-2.6116658858806496;3.778044...  \n",
       "11  -0.431035563823642;-3.133904864671361;5.480650...  \n",
       "12  1.5909275749162968;0.015245888235008375;3.1708...  \n",
       "13  1.5652473187723421;-1.1092173102934066;2.59331...  \n",
       "14  0.06275027285231641;-1.7262900077114107;2.2653...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 187.847152,
   "end_time": "2023-05-28T15:47:50.924894",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-28T15:44:43.077742",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
